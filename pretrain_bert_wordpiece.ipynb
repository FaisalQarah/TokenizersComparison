{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12e46f-23c8-4181-9e24-a0276dc12dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy==1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da4c2c-e801-4fa6-8676-c04e551ee88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.12\n",
    "!pip install pyarabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b7f2d-e4a6-4dc1-9a9f-eb0d99dc95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a42c50-df29-4c17-84f2-69da839d31e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install datasets\n",
    "!pip install transformers[torch]\n",
    "!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a49286b-4163-4b95-9c68-fdfe6aaa3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122dc8fb-4fb8-4065-8231-8cf429b81a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 08:34:23.581089: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-27 08:34:23.687709: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-27 08:34:24.407514: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc47f17-ea91-4dd0-93f8-83eade6763db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37167c88-b4f1-49d1-a315-0ffb3f1f436c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# importing and preprocessing text files (35.7 GB)\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pyarabic.araby as araby\n",
    "\n",
    "def remove_diacritics(a):    \n",
    "    return araby.strip_diacritics(a)\n",
    "\n",
    "def remove_tatweel(a):    \n",
    "    return araby.strip_tatweel(a)\n",
    "\n",
    "def remove_tashkeel(a):    \n",
    "    return araby.strip_tashkeel(a)\n",
    "\n",
    "#NOTE: convert to csv and save if for uploading\n",
    "folder_path = 'text/'\n",
    "file_list = glob.glob(folder_path + \"/*\")\n",
    "print(len(file_list))\n",
    "\n",
    "\n",
    "df = pd.read_csv(file_list[0], header = None, names=[\"text\"], sep='\\t')\n",
    "  \n",
    "for i in range(1,len(file_list)):  #len(file_list)\n",
    "# for i in range(len(file_list)):  #\n",
    "    print(i)\n",
    "    dff = pd.read_csv(file_list[i], header = None, names=[\"text\"], sep='\\t', )\n",
    "    # dff = pd.DataFrame(data)\n",
    "    df = pd.concat([df, dff], ignore_index=True, sort=False)\n",
    "    # pd.concat([dfc, dfc2], ignore_index=True, sort=False)\n",
    "  \n",
    "dff = dff[:1]\n",
    "\n",
    "df.fillna('', inplace=True)\n",
    "df = df[df['text'] != '']\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec70120-dea9-45ba-841d-fd50f6a46a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/home/ffq/.cache/huggingface/datasets/text/default-daa5a8d92e7d97fb/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275e0112f6574d449bad55f04ca6128a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizerFast, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import glob\n",
    "\n",
    "folder_path = 'text/'\n",
    "files_list = glob.glob(folder_path + \"/*\")\n",
    "dataset = load_dataset('text', data_files=files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce34f548-be5a-4e82-a8bf-c7b4703508b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 127836649\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084954b8-6733-4229-95b4-13e8e6131ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/home/ffq/.cache/huggingface/datasets/text/default-daa5a8d92e7d97fb/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b51c547a3974eb79f10bb2b626be055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 12784/12784 [07:59<00:00, 26.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bert_wordpiece/tokenizer_config.json',\n",
       " 'bert_wordpiece/special_tokens_map.json',\n",
       " 'bert_wordpiece/vocab.txt',\n",
       " 'bert_wordpiece/added_tokens.json',\n",
       " 'bert_wordpiece/tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizerFast, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import glob\n",
    "\n",
    "#loading bert tokenizer to work as a base for the new tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "folder_path = 'text/'\n",
    "files_list = glob.glob(folder_path + \"/*\")\n",
    "dataset = load_dataset('text', data_files=files_list)\n",
    "\n",
    "def batch_iterator(batch_size=10000):\n",
    "    for i in tqdm(range(0, len(dataset['train']), batch_size)):\n",
    "        yield dataset['train'][i: i +batch_size]['text']\n",
    "bert_tokenizer = tokenizer.train_new_from_iterator(text_iterator=batch_iterator(), \n",
    "                                                   vocab_size=50000\n",
    "                                                   #, special_tokens=['[CLS]', '[PAD]','[SEP]','[UNK]','[MASK]']\n",
    "                                                  )\n",
    "bert_tokenizer.save_pretrained('bert_wordpiece/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e8cdcd-050c-4b35-85be-aa8b9ad5cb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 17:55:48.183349: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-27 17:55:48.547709: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-27 17:55:49.129578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Found cached dataset text (/home/ffq/.cache/huggingface/datasets/text/default-daa5a8d92e7d97fb/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6da757e891d4f06b2d86ea838f869b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/127836649 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "127836649"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell-3\n",
    "#tokenizing the whole text \n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "from datasets import load_dataset\n",
    "import glob\n",
    "import tokenizers\n",
    "from transformers import Trainer, TrainingArguments, LineByLineTextDataset, BertModel\n",
    "from transformers import BertConfig, BertForMaskedLM, DataCollatorForLanguageModeling\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('faisalq/bert-base-arapoembert')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert_wordpiece/')\n",
    "max_seq_length = 128\n",
    "\n",
    "folder_path = 'text/'\n",
    "files_list = glob.glob(folder_path + \"/*\")\n",
    "dataset = load_dataset('text', data_files=files_list)\n",
    "\n",
    "# use to combine files: cat ./* > merged_file\n",
    "\n",
    "def encode_with_truncation(examples):\n",
    "  return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\",\n",
    "                   max_length=max_seq_length, return_special_tokens_mask=True)\n",
    "\n",
    "\n",
    "dataset = dataset[\"train\"].map(encode_with_truncation, batched=True)\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "# dataset = LineByLineTextDataset(tokenizer = tokenizer, file_path = 'text/text4.txt', \n",
    "#                                block_size = max_seq_length)\n",
    "display(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91036f0-2cdc-444e-a5ab-33c6fe4da9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'special_tokens_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a4de99-d5cf-48a2-b7d0-e187e8acc341",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be026e91-c580-4b44-878b-3a52027c3aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12fa0bec-b595-4c65-8e58-cd5060d0d83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/234 shards):   0%|          | 0/127836649 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(\"tokenized_dataset_wordpiece/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2f1916-098c-4603-afa8-cad135901655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 14:33:08.340737: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-29 14:33:08.729323: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-29 14:33:09.322681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#start here\n",
    "\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "from datasets import load_dataset\n",
    "import glob\n",
    "import tokenizers\n",
    "from transformers import Trainer, TrainingArguments, LineByLineTextDataset, BertModel\n",
    "from transformers import BertConfig, BertForMaskedLM, DataCollatorForLanguageModeling\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "dataset = load_from_disk(\"tokenized_dataset_wordpiece/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec45482-b6f0-4281-9f55-829fa6d1eb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124197968"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell-4\n",
    "# model config\n",
    "max_seq_length = 128\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert_wordpiece/')\n",
    "config = BertConfig( vocab_size = 50000, \n",
    "                    hidden_size = 768, \n",
    "                    num_hidden_layers = 12,\n",
    "                    num_attention_heads = 12,\n",
    "                    max_position_embeddings = max_seq_length)\n",
    "\n",
    "model = BertForMaskedLM(config)\n",
    "display(model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3adb1308-d307-40a5-af17-6fbd936a5701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ffq/miniconda3/envs/p1/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1997448' max='1997448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1997448/1997448 128:51:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>3.444800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>3.421500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>3.405100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160000</td>\n",
       "      <td>3.388900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165000</td>\n",
       "      <td>3.371900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170000</td>\n",
       "      <td>3.355400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175000</td>\n",
       "      <td>3.341500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180000</td>\n",
       "      <td>3.327000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185000</td>\n",
       "      <td>3.311100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190000</td>\n",
       "      <td>3.294300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195000</td>\n",
       "      <td>3.281700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200000</td>\n",
       "      <td>3.269500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205000</td>\n",
       "      <td>3.255500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210000</td>\n",
       "      <td>3.245700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215000</td>\n",
       "      <td>3.235600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220000</td>\n",
       "      <td>3.222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225000</td>\n",
       "      <td>3.215500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230000</td>\n",
       "      <td>3.203200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235000</td>\n",
       "      <td>3.193000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240000</td>\n",
       "      <td>3.180700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245000</td>\n",
       "      <td>3.172800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250000</td>\n",
       "      <td>3.162600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255000</td>\n",
       "      <td>3.156300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260000</td>\n",
       "      <td>3.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265000</td>\n",
       "      <td>3.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270000</td>\n",
       "      <td>3.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275000</td>\n",
       "      <td>3.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280000</td>\n",
       "      <td>3.114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285000</td>\n",
       "      <td>3.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290000</td>\n",
       "      <td>3.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295000</td>\n",
       "      <td>3.086700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300000</td>\n",
       "      <td>3.086300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305000</td>\n",
       "      <td>3.074600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310000</td>\n",
       "      <td>3.067500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315000</td>\n",
       "      <td>3.058400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320000</td>\n",
       "      <td>3.053200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325000</td>\n",
       "      <td>3.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330000</td>\n",
       "      <td>3.041300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335000</td>\n",
       "      <td>3.034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340000</td>\n",
       "      <td>3.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345000</td>\n",
       "      <td>3.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350000</td>\n",
       "      <td>3.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355000</td>\n",
       "      <td>3.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360000</td>\n",
       "      <td>3.007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365000</td>\n",
       "      <td>2.997100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370000</td>\n",
       "      <td>2.990500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375000</td>\n",
       "      <td>2.985900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380000</td>\n",
       "      <td>2.980800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385000</td>\n",
       "      <td>2.978700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390000</td>\n",
       "      <td>2.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395000</td>\n",
       "      <td>2.969500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400000</td>\n",
       "      <td>2.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405000</td>\n",
       "      <td>2.958700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410000</td>\n",
       "      <td>2.954600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415000</td>\n",
       "      <td>2.950100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420000</td>\n",
       "      <td>2.942300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425000</td>\n",
       "      <td>2.937200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430000</td>\n",
       "      <td>2.936100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435000</td>\n",
       "      <td>2.929300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440000</td>\n",
       "      <td>2.921500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445000</td>\n",
       "      <td>2.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450000</td>\n",
       "      <td>2.919500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455000</td>\n",
       "      <td>2.908600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460000</td>\n",
       "      <td>2.904900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465000</td>\n",
       "      <td>2.900800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470000</td>\n",
       "      <td>2.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475000</td>\n",
       "      <td>2.892500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480000</td>\n",
       "      <td>2.890200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485000</td>\n",
       "      <td>2.886900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490000</td>\n",
       "      <td>2.876800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495000</td>\n",
       "      <td>2.878100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500000</td>\n",
       "      <td>2.875300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505000</td>\n",
       "      <td>2.869800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510000</td>\n",
       "      <td>2.865700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515000</td>\n",
       "      <td>2.863400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520000</td>\n",
       "      <td>2.857700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525000</td>\n",
       "      <td>2.855500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530000</td>\n",
       "      <td>2.853900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535000</td>\n",
       "      <td>2.850700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540000</td>\n",
       "      <td>2.842400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545000</td>\n",
       "      <td>2.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550000</td>\n",
       "      <td>2.837900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555000</td>\n",
       "      <td>2.836200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560000</td>\n",
       "      <td>2.832700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565000</td>\n",
       "      <td>2.826900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570000</td>\n",
       "      <td>2.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575000</td>\n",
       "      <td>2.819100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580000</td>\n",
       "      <td>2.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585000</td>\n",
       "      <td>2.814600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590000</td>\n",
       "      <td>2.810800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595000</td>\n",
       "      <td>2.809700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600000</td>\n",
       "      <td>2.804700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605000</td>\n",
       "      <td>2.798600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610000</td>\n",
       "      <td>2.791800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615000</td>\n",
       "      <td>2.790800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620000</td>\n",
       "      <td>2.790800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625000</td>\n",
       "      <td>2.786200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630000</td>\n",
       "      <td>2.785500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635000</td>\n",
       "      <td>2.779900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640000</td>\n",
       "      <td>2.782100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>645000</td>\n",
       "      <td>2.779900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650000</td>\n",
       "      <td>2.773500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>655000</td>\n",
       "      <td>2.772800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660000</td>\n",
       "      <td>2.766500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665000</td>\n",
       "      <td>2.769400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670000</td>\n",
       "      <td>2.761300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675000</td>\n",
       "      <td>2.758400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680000</td>\n",
       "      <td>2.756700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685000</td>\n",
       "      <td>2.751600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690000</td>\n",
       "      <td>2.754600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695000</td>\n",
       "      <td>2.748200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700000</td>\n",
       "      <td>2.745300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705000</td>\n",
       "      <td>2.743200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710000</td>\n",
       "      <td>2.739900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715000</td>\n",
       "      <td>2.743700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720000</td>\n",
       "      <td>2.736500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725000</td>\n",
       "      <td>2.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730000</td>\n",
       "      <td>2.733400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735000</td>\n",
       "      <td>2.725900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740000</td>\n",
       "      <td>2.727500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745000</td>\n",
       "      <td>2.720700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750000</td>\n",
       "      <td>2.722300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755000</td>\n",
       "      <td>2.720900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760000</td>\n",
       "      <td>2.711600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765000</td>\n",
       "      <td>2.719200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770000</td>\n",
       "      <td>2.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775000</td>\n",
       "      <td>2.709900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780000</td>\n",
       "      <td>2.711400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>785000</td>\n",
       "      <td>2.712300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790000</td>\n",
       "      <td>2.709100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795000</td>\n",
       "      <td>2.702200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800000</td>\n",
       "      <td>2.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805000</td>\n",
       "      <td>2.700300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810000</td>\n",
       "      <td>2.696400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815000</td>\n",
       "      <td>2.693900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820000</td>\n",
       "      <td>2.687200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825000</td>\n",
       "      <td>2.689600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830000</td>\n",
       "      <td>2.689500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835000</td>\n",
       "      <td>2.686600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840000</td>\n",
       "      <td>2.684200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845000</td>\n",
       "      <td>2.681600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850000</td>\n",
       "      <td>2.675500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>855000</td>\n",
       "      <td>2.678500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860000</td>\n",
       "      <td>2.676400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>865000</td>\n",
       "      <td>2.674900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870000</td>\n",
       "      <td>2.668100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875000</td>\n",
       "      <td>2.667800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880000</td>\n",
       "      <td>2.664900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885000</td>\n",
       "      <td>2.663500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890000</td>\n",
       "      <td>2.662300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895000</td>\n",
       "      <td>2.658900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900000</td>\n",
       "      <td>2.655300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>905000</td>\n",
       "      <td>2.655800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910000</td>\n",
       "      <td>2.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>915000</td>\n",
       "      <td>2.647300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920000</td>\n",
       "      <td>2.648400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925000</td>\n",
       "      <td>2.646200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930000</td>\n",
       "      <td>2.643500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935000</td>\n",
       "      <td>2.641600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940000</td>\n",
       "      <td>2.638700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>945000</td>\n",
       "      <td>2.636300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950000</td>\n",
       "      <td>2.635300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>955000</td>\n",
       "      <td>2.636500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960000</td>\n",
       "      <td>2.633800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>965000</td>\n",
       "      <td>2.633100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970000</td>\n",
       "      <td>2.632200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975000</td>\n",
       "      <td>2.627700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980000</td>\n",
       "      <td>2.624300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>985000</td>\n",
       "      <td>2.622800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990000</td>\n",
       "      <td>2.619300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995000</td>\n",
       "      <td>2.619600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000000</td>\n",
       "      <td>2.617300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1005000</td>\n",
       "      <td>2.613300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010000</td>\n",
       "      <td>2.617200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1015000</td>\n",
       "      <td>2.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020000</td>\n",
       "      <td>2.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025000</td>\n",
       "      <td>2.603300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030000</td>\n",
       "      <td>2.602100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1035000</td>\n",
       "      <td>2.603400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040000</td>\n",
       "      <td>2.597400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1045000</td>\n",
       "      <td>2.600500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050000</td>\n",
       "      <td>2.597000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1055000</td>\n",
       "      <td>2.597800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060000</td>\n",
       "      <td>2.591900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1065000</td>\n",
       "      <td>2.591600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070000</td>\n",
       "      <td>2.587900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075000</td>\n",
       "      <td>2.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080000</td>\n",
       "      <td>2.585600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1085000</td>\n",
       "      <td>2.587100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090000</td>\n",
       "      <td>2.586500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1095000</td>\n",
       "      <td>2.584800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100000</td>\n",
       "      <td>2.584300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1105000</td>\n",
       "      <td>2.580800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110000</td>\n",
       "      <td>2.579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1115000</td>\n",
       "      <td>2.574700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120000</td>\n",
       "      <td>2.574100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125000</td>\n",
       "      <td>2.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130000</td>\n",
       "      <td>2.569800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1135000</td>\n",
       "      <td>2.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140000</td>\n",
       "      <td>2.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1145000</td>\n",
       "      <td>2.567600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150000</td>\n",
       "      <td>2.562700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1155000</td>\n",
       "      <td>2.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160000</td>\n",
       "      <td>2.561500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1165000</td>\n",
       "      <td>2.557400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170000</td>\n",
       "      <td>2.557100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175000</td>\n",
       "      <td>2.554200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180000</td>\n",
       "      <td>2.554000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1185000</td>\n",
       "      <td>2.551900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190000</td>\n",
       "      <td>2.554200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1195000</td>\n",
       "      <td>2.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200000</td>\n",
       "      <td>2.548300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1205000</td>\n",
       "      <td>2.546500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210000</td>\n",
       "      <td>2.546400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1215000</td>\n",
       "      <td>2.542400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220000</td>\n",
       "      <td>2.543000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225000</td>\n",
       "      <td>2.544100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230000</td>\n",
       "      <td>2.536400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1235000</td>\n",
       "      <td>2.537400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240000</td>\n",
       "      <td>2.535100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1245000</td>\n",
       "      <td>2.535500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250000</td>\n",
       "      <td>2.529100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1255000</td>\n",
       "      <td>2.527200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260000</td>\n",
       "      <td>2.529500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1265000</td>\n",
       "      <td>2.529800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270000</td>\n",
       "      <td>2.521800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275000</td>\n",
       "      <td>2.525600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280000</td>\n",
       "      <td>2.524100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1285000</td>\n",
       "      <td>2.523200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290000</td>\n",
       "      <td>2.522800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1295000</td>\n",
       "      <td>2.520400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300000</td>\n",
       "      <td>2.519100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305000</td>\n",
       "      <td>2.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310000</td>\n",
       "      <td>2.516600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1315000</td>\n",
       "      <td>2.513600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320000</td>\n",
       "      <td>2.513200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325000</td>\n",
       "      <td>2.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330000</td>\n",
       "      <td>2.509700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1335000</td>\n",
       "      <td>2.507800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340000</td>\n",
       "      <td>2.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1345000</td>\n",
       "      <td>2.507200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350000</td>\n",
       "      <td>2.506700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1355000</td>\n",
       "      <td>2.500400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360000</td>\n",
       "      <td>2.499400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1365000</td>\n",
       "      <td>2.502600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370000</td>\n",
       "      <td>2.499400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375000</td>\n",
       "      <td>2.495400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1385000</td>\n",
       "      <td>2.492300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390000</td>\n",
       "      <td>2.492100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1395000</td>\n",
       "      <td>2.488400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400000</td>\n",
       "      <td>2.492900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1405000</td>\n",
       "      <td>2.489100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410000</td>\n",
       "      <td>2.486700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1415000</td>\n",
       "      <td>2.484400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420000</td>\n",
       "      <td>2.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425000</td>\n",
       "      <td>2.479700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430000</td>\n",
       "      <td>2.482600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1435000</td>\n",
       "      <td>2.482900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440000</td>\n",
       "      <td>2.481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1445000</td>\n",
       "      <td>2.479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450000</td>\n",
       "      <td>2.478400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455000</td>\n",
       "      <td>2.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460000</td>\n",
       "      <td>2.476100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1465000</td>\n",
       "      <td>2.476100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470000</td>\n",
       "      <td>2.477300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475000</td>\n",
       "      <td>2.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480000</td>\n",
       "      <td>2.469700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485000</td>\n",
       "      <td>2.471300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490000</td>\n",
       "      <td>2.468100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1495000</td>\n",
       "      <td>2.468500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500000</td>\n",
       "      <td>2.465300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505000</td>\n",
       "      <td>2.463100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510000</td>\n",
       "      <td>2.464900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1515000</td>\n",
       "      <td>2.461900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520000</td>\n",
       "      <td>2.462500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525000</td>\n",
       "      <td>2.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530000</td>\n",
       "      <td>2.461400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1535000</td>\n",
       "      <td>2.458000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540000</td>\n",
       "      <td>2.455100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1545000</td>\n",
       "      <td>2.455600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550000</td>\n",
       "      <td>2.454700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1555000</td>\n",
       "      <td>2.448800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560000</td>\n",
       "      <td>2.448900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1565000</td>\n",
       "      <td>2.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570000</td>\n",
       "      <td>2.446900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575000</td>\n",
       "      <td>2.449400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580000</td>\n",
       "      <td>2.445700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1585000</td>\n",
       "      <td>2.444500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590000</td>\n",
       "      <td>2.443800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1595000</td>\n",
       "      <td>2.442900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600000</td>\n",
       "      <td>2.443800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1605000</td>\n",
       "      <td>2.444600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610000</td>\n",
       "      <td>2.438200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1615000</td>\n",
       "      <td>2.439100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620000</td>\n",
       "      <td>2.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625000</td>\n",
       "      <td>2.437100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630000</td>\n",
       "      <td>2.437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1635000</td>\n",
       "      <td>2.437100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640000</td>\n",
       "      <td>2.430700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1645000</td>\n",
       "      <td>2.433700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650000</td>\n",
       "      <td>2.432500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1655000</td>\n",
       "      <td>2.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660000</td>\n",
       "      <td>2.426700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1665000</td>\n",
       "      <td>2.426300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670000</td>\n",
       "      <td>2.424000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675000</td>\n",
       "      <td>2.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680000</td>\n",
       "      <td>2.424800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1685000</td>\n",
       "      <td>2.423200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690000</td>\n",
       "      <td>2.424900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1695000</td>\n",
       "      <td>2.421800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700000</td>\n",
       "      <td>2.419700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1705000</td>\n",
       "      <td>2.417400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710000</td>\n",
       "      <td>2.420400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1715000</td>\n",
       "      <td>2.418600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720000</td>\n",
       "      <td>2.413100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725000</td>\n",
       "      <td>2.417100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730000</td>\n",
       "      <td>2.416200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1735000</td>\n",
       "      <td>2.412700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740000</td>\n",
       "      <td>2.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1745000</td>\n",
       "      <td>2.410900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750000</td>\n",
       "      <td>2.412200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1755000</td>\n",
       "      <td>2.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760000</td>\n",
       "      <td>2.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1765000</td>\n",
       "      <td>2.410700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770000</td>\n",
       "      <td>2.404800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775000</td>\n",
       "      <td>2.408500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780000</td>\n",
       "      <td>2.405100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1785000</td>\n",
       "      <td>2.400600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790000</td>\n",
       "      <td>2.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1795000</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800000</td>\n",
       "      <td>2.397700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1805000</td>\n",
       "      <td>2.399400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810000</td>\n",
       "      <td>2.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1815000</td>\n",
       "      <td>2.395400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820000</td>\n",
       "      <td>2.400100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825000</td>\n",
       "      <td>2.398500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830000</td>\n",
       "      <td>2.395600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1835000</td>\n",
       "      <td>2.395600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840000</td>\n",
       "      <td>2.397600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1845000</td>\n",
       "      <td>2.391500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850000</td>\n",
       "      <td>2.390800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1855000</td>\n",
       "      <td>2.391400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860000</td>\n",
       "      <td>2.391600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1865000</td>\n",
       "      <td>2.393100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870000</td>\n",
       "      <td>2.385800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875000</td>\n",
       "      <td>2.389500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880000</td>\n",
       "      <td>2.388800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1885000</td>\n",
       "      <td>2.386700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890000</td>\n",
       "      <td>2.388500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1895000</td>\n",
       "      <td>2.388800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900000</td>\n",
       "      <td>2.388300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1905000</td>\n",
       "      <td>2.383900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910000</td>\n",
       "      <td>2.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1915000</td>\n",
       "      <td>2.385200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920000</td>\n",
       "      <td>2.378900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925000</td>\n",
       "      <td>2.382100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930000</td>\n",
       "      <td>2.376100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1935000</td>\n",
       "      <td>2.382100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940000</td>\n",
       "      <td>2.382900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1945000</td>\n",
       "      <td>2.380900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950000</td>\n",
       "      <td>2.377900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1955000</td>\n",
       "      <td>2.377500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960000</td>\n",
       "      <td>2.377000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1965000</td>\n",
       "      <td>2.375500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970000</td>\n",
       "      <td>2.375500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975000</td>\n",
       "      <td>2.375900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980000</td>\n",
       "      <td>2.375700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1985000</td>\n",
       "      <td>2.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990000</td>\n",
       "      <td>2.376400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995000</td>\n",
       "      <td>2.377700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell-5\n",
    "#pretraining the model\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True,\n",
    "                                               mlm_probability=0.15)\n",
    "epochs = 2\n",
    "save_steps = 10000 #save checkpoint every 10000 steps\n",
    "batch_size = 128\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = 'bert_wordpiece/',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs = epochs,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    save_steps = save_steps,\n",
    "    save_total_limit = 2, #only save the last 5 checkpoints\n",
    "    fp16=True,\n",
    "    # tf32 = True,\n",
    "    learning_rate = 5e-5,  # 5e-5 is the default\n",
    "    logging_steps = 5_000,\n",
    "    # gradient_accumulation_steps=4,\n",
    "    # gradient_checkpointing=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset\n",
    "\n",
    ")\n",
    "\n",
    "from pynvml import *\n",
    "\n",
    "\n",
    "trainer.train(resume_from_checkpoint=True)\n",
    "# trainer.train()\n",
    "trainer.save_model('bert_wordpiece/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6319ddf3-b3da-463d-b864-475f07bc292d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e4714-2fdc-4e78-b39c-14f952210b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36de33-0b55-4e3c-bd75-764b9deab7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff12a54-3b7f-4e72-8843-e2d196f4df26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
