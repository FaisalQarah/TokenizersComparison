{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 07:41:32.489648: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-20 07:41:32.515396: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 07:41:32.879376: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Class', 'Content', 'ID', 'Platform'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'art-and-entertainment',\n",
       " 'business-and-economy',\n",
       " 'crime-war-conflict',\n",
       " 'education',\n",
       " 'environment',\n",
       " 'health',\n",
       " 'human-rights-press-freedom',\n",
       " 'others',\n",
       " 'politics',\n",
       " 'science-and-technology',\n",
       " 'spiritual',\n",
       " 'sports'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6676"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1670"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Content', 'label'],\n",
       "    num_rows: 6676\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Content', 'label'],\n",
       "    num_rows: 1670\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 01:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.610100</td>\n",
       "      <td>1.087461</td>\n",
       "      <td>0.668263</td>\n",
       "      <td>0.230326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.017400</td>\n",
       "      <td>0.777988</td>\n",
       "      <td>0.768263</td>\n",
       "      <td>0.522362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.748400</td>\n",
       "      <td>0.669011</td>\n",
       "      <td>0.786826</td>\n",
       "      <td>0.627658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.629300</td>\n",
       "      <td>0.585167</td>\n",
       "      <td>0.818563</td>\n",
       "      <td>0.754481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.560500</td>\n",
       "      <td>0.565988</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.761701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.465400</td>\n",
       "      <td>0.556855</td>\n",
       "      <td>0.816168</td>\n",
       "      <td>0.767864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.397600</td>\n",
       "      <td>0.560186</td>\n",
       "      <td>0.817365</td>\n",
       "      <td>0.769506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.411100</td>\n",
       "      <td>0.578475</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.770847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.294600</td>\n",
       "      <td>0.577097</td>\n",
       "      <td>0.816168</td>\n",
       "      <td>0.774904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.290400</td>\n",
       "      <td>0.600861</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.768895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.602830</td>\n",
       "      <td>0.810180</td>\n",
       "      <td>0.778968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.622983</td>\n",
       "      <td>0.816168</td>\n",
       "      <td>0.771938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.635870</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.778405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.660902</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.771811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.685742</td>\n",
       "      <td>0.816766</td>\n",
       "      <td>0.773622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.200800</td>\n",
       "      <td>0.679013</td>\n",
       "      <td>0.817365</td>\n",
       "      <td>0.784175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.684968</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.775901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.697457</td>\n",
       "      <td>0.810180</td>\n",
       "      <td>0.769888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>0.723506</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.778841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.729553</td>\n",
       "      <td>0.807784</td>\n",
       "      <td>0.777348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.728382</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.772196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.741605</td>\n",
       "      <td>0.802994</td>\n",
       "      <td>0.770443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.742635</td>\n",
       "      <td>0.807784</td>\n",
       "      <td>0.779705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.801198</td>\n",
       "      <td>0.772952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.752324</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.773813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.759173</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.778024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.111700</td>\n",
       "      <td>0.759989</td>\n",
       "      <td>0.802994</td>\n",
       "      <td>0.773215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 01:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.635100</td>\n",
       "      <td>1.099874</td>\n",
       "      <td>0.666467</td>\n",
       "      <td>0.202787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.030200</td>\n",
       "      <td>0.796080</td>\n",
       "      <td>0.757485</td>\n",
       "      <td>0.520026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.756700</td>\n",
       "      <td>0.669730</td>\n",
       "      <td>0.789820</td>\n",
       "      <td>0.622655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.644300</td>\n",
       "      <td>0.588982</td>\n",
       "      <td>0.815569</td>\n",
       "      <td>0.723831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.562200</td>\n",
       "      <td>0.558433</td>\n",
       "      <td>0.823353</td>\n",
       "      <td>0.786759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.469800</td>\n",
       "      <td>0.546292</td>\n",
       "      <td>0.823353</td>\n",
       "      <td>0.775919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.551110</td>\n",
       "      <td>0.828144</td>\n",
       "      <td>0.782857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.566931</td>\n",
       "      <td>0.812575</td>\n",
       "      <td>0.782978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.581156</td>\n",
       "      <td>0.819760</td>\n",
       "      <td>0.778495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.605712</td>\n",
       "      <td>0.808982</td>\n",
       "      <td>0.777892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.319600</td>\n",
       "      <td>0.601083</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.777167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.632138</td>\n",
       "      <td>0.814970</td>\n",
       "      <td>0.764961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.643092</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.770280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.642732</td>\n",
       "      <td>0.803593</td>\n",
       "      <td>0.770283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.674176</td>\n",
       "      <td>0.816168</td>\n",
       "      <td>0.781191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.191800</td>\n",
       "      <td>0.691621</td>\n",
       "      <td>0.819162</td>\n",
       "      <td>0.778056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.700847</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.780315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.711931</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.768792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.727574</td>\n",
       "      <td>0.801796</td>\n",
       "      <td>0.771384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.735594</td>\n",
       "      <td>0.801796</td>\n",
       "      <td>0.770348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.735705</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.773027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.747956</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.771336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.747291</td>\n",
       "      <td>0.804790</td>\n",
       "      <td>0.771908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.119100</td>\n",
       "      <td>0.750539</td>\n",
       "      <td>0.801796</td>\n",
       "      <td>0.768563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.751542</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.771376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.762185</td>\n",
       "      <td>0.804790</td>\n",
       "      <td>0.772019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.762618</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.771415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 01:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.635100</td>\n",
       "      <td>1.099874</td>\n",
       "      <td>0.666467</td>\n",
       "      <td>0.202787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.030200</td>\n",
       "      <td>0.796080</td>\n",
       "      <td>0.757485</td>\n",
       "      <td>0.520026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.756700</td>\n",
       "      <td>0.669730</td>\n",
       "      <td>0.789820</td>\n",
       "      <td>0.622655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.644300</td>\n",
       "      <td>0.588982</td>\n",
       "      <td>0.815569</td>\n",
       "      <td>0.723831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.562200</td>\n",
       "      <td>0.558433</td>\n",
       "      <td>0.823353</td>\n",
       "      <td>0.786759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.469800</td>\n",
       "      <td>0.546292</td>\n",
       "      <td>0.823353</td>\n",
       "      <td>0.775919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.551110</td>\n",
       "      <td>0.828144</td>\n",
       "      <td>0.782857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.566931</td>\n",
       "      <td>0.812575</td>\n",
       "      <td>0.782978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.581156</td>\n",
       "      <td>0.819760</td>\n",
       "      <td>0.778495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.605712</td>\n",
       "      <td>0.808982</td>\n",
       "      <td>0.777892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.319600</td>\n",
       "      <td>0.601083</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.777167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.632138</td>\n",
       "      <td>0.814970</td>\n",
       "      <td>0.764961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.643092</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.770280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.642732</td>\n",
       "      <td>0.803593</td>\n",
       "      <td>0.770283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.674176</td>\n",
       "      <td>0.816168</td>\n",
       "      <td>0.781191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.191800</td>\n",
       "      <td>0.691621</td>\n",
       "      <td>0.819162</td>\n",
       "      <td>0.778056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.700847</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.780315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.711931</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.768792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.727574</td>\n",
       "      <td>0.801796</td>\n",
       "      <td>0.771384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.735594</td>\n",
       "      <td>0.801796</td>\n",
       "      <td>0.770348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.735705</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.773027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.747956</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.771336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.747291</td>\n",
       "      <td>0.804790</td>\n",
       "      <td>0.771908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.119100</td>\n",
       "      <td>0.750539</td>\n",
       "      <td>0.801796</td>\n",
       "      <td>0.768563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.751542</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.771376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.762185</td>\n",
       "      <td>0.804790</td>\n",
       "      <td>0.772019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.762618</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.771415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 01:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.667700</td>\n",
       "      <td>1.117341</td>\n",
       "      <td>0.655090</td>\n",
       "      <td>0.209539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.020600</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.758084</td>\n",
       "      <td>0.469469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.770200</td>\n",
       "      <td>0.689111</td>\n",
       "      <td>0.777246</td>\n",
       "      <td>0.559880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.636300</td>\n",
       "      <td>0.596705</td>\n",
       "      <td>0.810180</td>\n",
       "      <td>0.689445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.567600</td>\n",
       "      <td>0.575316</td>\n",
       "      <td>0.809581</td>\n",
       "      <td>0.768878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.480100</td>\n",
       "      <td>0.568056</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.778932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.557461</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.782792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.585563</td>\n",
       "      <td>0.808982</td>\n",
       "      <td>0.777972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.587702</td>\n",
       "      <td>0.812575</td>\n",
       "      <td>0.775225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>0.592413</td>\n",
       "      <td>0.807784</td>\n",
       "      <td>0.772670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.609325</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.776759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.198300</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.809581</td>\n",
       "      <td>0.769022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.648389</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.776058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.636289</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.769383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.174100</td>\n",
       "      <td>0.674516</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.777553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.692029</td>\n",
       "      <td>0.801796</td>\n",
       "      <td>0.770097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.701387</td>\n",
       "      <td>0.802994</td>\n",
       "      <td>0.780076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.695785</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.770517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.693197</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.781831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.719180</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.780551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.776007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.763080</td>\n",
       "      <td>0.804192</td>\n",
       "      <td>0.775026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.770522</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.776676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.769434</td>\n",
       "      <td>0.801796</td>\n",
       "      <td>0.771460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.768914</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.773065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.774826</td>\n",
       "      <td>0.804192</td>\n",
       "      <td>0.775898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>0.776170</td>\n",
       "      <td>0.803593</td>\n",
       "      <td>0.773111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 01:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.667700</td>\n",
       "      <td>1.117341</td>\n",
       "      <td>0.655090</td>\n",
       "      <td>0.209539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.020600</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.758084</td>\n",
       "      <td>0.469469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.770200</td>\n",
       "      <td>0.689111</td>\n",
       "      <td>0.777246</td>\n",
       "      <td>0.559880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.636300</td>\n",
       "      <td>0.596705</td>\n",
       "      <td>0.810180</td>\n",
       "      <td>0.689445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.567600</td>\n",
       "      <td>0.575316</td>\n",
       "      <td>0.809581</td>\n",
       "      <td>0.768878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.480100</td>\n",
       "      <td>0.568056</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.778932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.557461</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.782792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.585563</td>\n",
       "      <td>0.808982</td>\n",
       "      <td>0.777972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.587702</td>\n",
       "      <td>0.812575</td>\n",
       "      <td>0.775225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>0.592413</td>\n",
       "      <td>0.807784</td>\n",
       "      <td>0.772670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.609325</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.776759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.198300</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.809581</td>\n",
       "      <td>0.769022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.648389</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.776058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.636289</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.769383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.174100</td>\n",
       "      <td>0.674516</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.777553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.692029</td>\n",
       "      <td>0.801796</td>\n",
       "      <td>0.770097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.701387</td>\n",
       "      <td>0.802994</td>\n",
       "      <td>0.780076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.695785</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.770517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.693197</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.781831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.719180</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.780551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.776007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.763080</td>\n",
       "      <td>0.804192</td>\n",
       "      <td>0.775026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.770522</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.776676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.769434</td>\n",
       "      <td>0.801796</td>\n",
       "      <td>0.771460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.768914</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.773065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.774826</td>\n",
       "      <td>0.804192</td>\n",
       "      <td>0.775898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>0.776170</td>\n",
       "      <td>0.803593</td>\n",
       "      <td>0.773111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 01:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.667700</td>\n",
       "      <td>1.117341</td>\n",
       "      <td>0.655090</td>\n",
       "      <td>0.209539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.020600</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.758084</td>\n",
       "      <td>0.469469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.770200</td>\n",
       "      <td>0.689111</td>\n",
       "      <td>0.777246</td>\n",
       "      <td>0.559880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.636300</td>\n",
       "      <td>0.596705</td>\n",
       "      <td>0.810180</td>\n",
       "      <td>0.689445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.567600</td>\n",
       "      <td>0.575316</td>\n",
       "      <td>0.809581</td>\n",
       "      <td>0.768878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.480100</td>\n",
       "      <td>0.568056</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.778932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.557461</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.782792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.585563</td>\n",
       "      <td>0.808982</td>\n",
       "      <td>0.777972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.587702</td>\n",
       "      <td>0.812575</td>\n",
       "      <td>0.775225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>0.592413</td>\n",
       "      <td>0.807784</td>\n",
       "      <td>0.772670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.609325</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.776759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.198300</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.809581</td>\n",
       "      <td>0.769022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.648389</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.776058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.636289</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.769383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.174100</td>\n",
       "      <td>0.674516</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.777553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.692029</td>\n",
       "      <td>0.801796</td>\n",
       "      <td>0.770097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.701387</td>\n",
       "      <td>0.802994</td>\n",
       "      <td>0.780076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.695785</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.770517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.693197</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.781831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.719180</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.780551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.776007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.763080</td>\n",
       "      <td>0.804192</td>\n",
       "      <td>0.775026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.770522</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.776676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.769434</td>\n",
       "      <td>0.801796</td>\n",
       "      <td>0.771460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.768914</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.773065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.774826</td>\n",
       "      <td>0.804192</td>\n",
       "      <td>0.775898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>0.776170</td>\n",
       "      <td>0.803593</td>\n",
       "      <td>0.773111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 01:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.656400</td>\n",
       "      <td>1.135584</td>\n",
       "      <td>0.650898</td>\n",
       "      <td>0.178589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.025800</td>\n",
       "      <td>0.817475</td>\n",
       "      <td>0.757485</td>\n",
       "      <td>0.500853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.690758</td>\n",
       "      <td>0.792814</td>\n",
       "      <td>0.635280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.638600</td>\n",
       "      <td>0.611391</td>\n",
       "      <td>0.802994</td>\n",
       "      <td>0.689639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.564100</td>\n",
       "      <td>0.576517</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.755053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>0.575279</td>\n",
       "      <td>0.812575</td>\n",
       "      <td>0.764960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.410200</td>\n",
       "      <td>0.562574</td>\n",
       "      <td>0.816766</td>\n",
       "      <td>0.773670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.416100</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.777300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.296600</td>\n",
       "      <td>0.576321</td>\n",
       "      <td>0.817365</td>\n",
       "      <td>0.775912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.292800</td>\n",
       "      <td>0.603757</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.763455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.604745</td>\n",
       "      <td>0.819162</td>\n",
       "      <td>0.785417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.620822</td>\n",
       "      <td>0.816766</td>\n",
       "      <td>0.782207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.239800</td>\n",
       "      <td>0.649134</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.778932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.201600</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.807784</td>\n",
       "      <td>0.774046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.653762</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.775206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.772284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.684307</td>\n",
       "      <td>0.813772</td>\n",
       "      <td>0.788509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.698166</td>\n",
       "      <td>0.810180</td>\n",
       "      <td>0.781019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.713061</td>\n",
       "      <td>0.804790</td>\n",
       "      <td>0.775858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.722326</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.779237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.726885</td>\n",
       "      <td>0.815569</td>\n",
       "      <td>0.785998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.743300</td>\n",
       "      <td>0.808982</td>\n",
       "      <td>0.784592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.751055</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.779155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.749055</td>\n",
       "      <td>0.803593</td>\n",
       "      <td>0.774138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.748727</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.774347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.762389</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.781209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.107600</td>\n",
       "      <td>0.762665</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.780751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 01:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.656400</td>\n",
       "      <td>1.135584</td>\n",
       "      <td>0.650898</td>\n",
       "      <td>0.178589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.025800</td>\n",
       "      <td>0.817475</td>\n",
       "      <td>0.757485</td>\n",
       "      <td>0.500853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.690758</td>\n",
       "      <td>0.792814</td>\n",
       "      <td>0.635280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.638600</td>\n",
       "      <td>0.611391</td>\n",
       "      <td>0.802994</td>\n",
       "      <td>0.689639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.564100</td>\n",
       "      <td>0.576517</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.755053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>0.575279</td>\n",
       "      <td>0.812575</td>\n",
       "      <td>0.764960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.410200</td>\n",
       "      <td>0.562574</td>\n",
       "      <td>0.816766</td>\n",
       "      <td>0.773670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.416100</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.777300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.296600</td>\n",
       "      <td>0.576321</td>\n",
       "      <td>0.817365</td>\n",
       "      <td>0.775912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.292800</td>\n",
       "      <td>0.603757</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.763455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.604745</td>\n",
       "      <td>0.819162</td>\n",
       "      <td>0.785417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.620822</td>\n",
       "      <td>0.816766</td>\n",
       "      <td>0.782207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.239800</td>\n",
       "      <td>0.649134</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.778932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.201600</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.807784</td>\n",
       "      <td>0.774046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.653762</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.775206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.772284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.684307</td>\n",
       "      <td>0.813772</td>\n",
       "      <td>0.788509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.698166</td>\n",
       "      <td>0.810180</td>\n",
       "      <td>0.781019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.713061</td>\n",
       "      <td>0.804790</td>\n",
       "      <td>0.775858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.722326</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.779237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.726885</td>\n",
       "      <td>0.815569</td>\n",
       "      <td>0.785998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.743300</td>\n",
       "      <td>0.808982</td>\n",
       "      <td>0.784592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.751055</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.779155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.749055</td>\n",
       "      <td>0.803593</td>\n",
       "      <td>0.774138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.748727</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.774347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.762389</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.781209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.107600</td>\n",
       "      <td>0.762665</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.780751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 01:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.656400</td>\n",
       "      <td>1.135584</td>\n",
       "      <td>0.650898</td>\n",
       "      <td>0.178589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.025800</td>\n",
       "      <td>0.817475</td>\n",
       "      <td>0.757485</td>\n",
       "      <td>0.500853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.690758</td>\n",
       "      <td>0.792814</td>\n",
       "      <td>0.635280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.638600</td>\n",
       "      <td>0.611391</td>\n",
       "      <td>0.802994</td>\n",
       "      <td>0.689639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.564100</td>\n",
       "      <td>0.576517</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.755053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>0.575279</td>\n",
       "      <td>0.812575</td>\n",
       "      <td>0.764960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.410200</td>\n",
       "      <td>0.562574</td>\n",
       "      <td>0.816766</td>\n",
       "      <td>0.773670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.416100</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.777300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.296600</td>\n",
       "      <td>0.576321</td>\n",
       "      <td>0.817365</td>\n",
       "      <td>0.775912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.292800</td>\n",
       "      <td>0.603757</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.763455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.604745</td>\n",
       "      <td>0.819162</td>\n",
       "      <td>0.785417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.620822</td>\n",
       "      <td>0.816766</td>\n",
       "      <td>0.782207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.239800</td>\n",
       "      <td>0.649134</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.778932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.201600</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.807784</td>\n",
       "      <td>0.774046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.653762</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.775206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.772284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.684307</td>\n",
       "      <td>0.813772</td>\n",
       "      <td>0.788509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.698166</td>\n",
       "      <td>0.810180</td>\n",
       "      <td>0.781019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.713061</td>\n",
       "      <td>0.804790</td>\n",
       "      <td>0.775858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.722326</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.779237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.726885</td>\n",
       "      <td>0.815569</td>\n",
       "      <td>0.785998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.743300</td>\n",
       "      <td>0.808982</td>\n",
       "      <td>0.784592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.751055</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.779155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.749055</td>\n",
       "      <td>0.803593</td>\n",
       "      <td>0.774138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.748727</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.774347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.762389</td>\n",
       "      <td>0.805988</td>\n",
       "      <td>0.781209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.107600</td>\n",
       "      <td>0.762665</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.780751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faisalq/bert-base-arabic-bbpe</td>\n",
       "      <td>0.813772</td>\n",
       "      <td>0.788509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>faisalq/bert-base-arabic-senpiece</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.782792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/bert-base-arabic-wordpiece</td>\n",
       "      <td>0.823353</td>\n",
       "      <td>0.786759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  Accuracy        F1\n",
       "0       faisalq/bert-base-arabic-bbpe  0.813772  0.788509\n",
       "3   faisalq/bert-base-arabic-senpiece  0.811976  0.782792\n",
       "6  faisalq/bert-base-arabic-wordpiece  0.823353  0.786759"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell-1  \n",
    "#load and clean the data (removing diacritics and unwanted text)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "log_file = 'ASND.txt'\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "\n",
    "# ds = load_dataset('hard')\n",
    "\n",
    "df = pd.read_csv('ASND/sm_news_ar_trn.csv', encoding='utf-8', engine='python') #, quotechar=\"'\"  , quoting=3\n",
    "display(df.columns)\n",
    "df2 = pd.read_csv('ASND/sm_news_ar_dev.csv', encoding='utf-8', engine='python') #, quotechar=\"'\"  , quoting=3\n",
    "df3 = pd.read_csv('ASND/sm_news_ar_tst.csv', encoding='utf-8', engine='python') #, quotechar=\"'\"  , quoting=3\n",
    "\n",
    "df_test = pd.concat([df2, df3], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "classes = set(df['Class'].values)\n",
    "display(classes)\n",
    "\n",
    "df['Class'] = df['Class'].astype('category')\n",
    "df['label'] = df['Class'].cat.codes\n",
    "\n",
    "\n",
    "df_test['Class'] = df_test['Class'].astype('category')\n",
    "df_test['label'] = df_test['Class'].cat.codes\n",
    "\n",
    "df = df[['Content', 'label']]\n",
    "df_test = df_test[['Content', 'label']]\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "display(len(df_test))\n",
    "\n",
    "\n",
    "ds_t = Dataset.from_pandas(df)\n",
    "ds_v = Dataset.from_pandas(df_test)\n",
    "\n",
    "# ds = ds['train']\n",
    "# ds = ds.train_test_split(test_size=0.2)\n",
    "display(ds_t)\n",
    "display(ds_v)\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "# classes_num = 6\n",
    "# display(classes_num)\n",
    "# display(ds)\n",
    "\n",
    "\n",
    "models = ['faisalq/bert-base-arabic-wordpiece', 'faisalq/bert-base-arabic-senpiece',\n",
    "          'faisalq/bert-base-arabic-bbpe']\n",
    "\n",
    "\n",
    "for model_name in models:\n",
    "    for i in range(3):\n",
    "        print(f'{model_name}, try:{i}')\n",
    "              \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = BertForSequenceClassification.from_pretrained(model_name,\n",
    "                                                              num_labels=classes_num).to('cuda')                                                 \n",
    "        dataset_train = ds_t\n",
    "        dataset_validation = ds_v                                                     \n",
    "        \n",
    "      \n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            return tokenizer(examples['Content'], truncation=True, padding=\"max_length\",\n",
    "                            max_length=max_sequence_length)\n",
    "        \n",
    "        \n",
    "        dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "        dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "        \n",
    "       \n",
    "        \n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)    \n",
    "            acc = accuracy_score(labels, predictions)        \n",
    "            f1 = f1_score(labels, predictions, average='macro')   \n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{model_name},{acc},{f1}\\n')\n",
    "            return {'accuracy': acc, 'f1_score': f1}\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        epochs = 10\n",
    "        save_steps = 10000 #save checkpoint every 10000 steps\n",
    "        batch_size = 256\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = 'bert/',\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs = epochs,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            save_steps = save_steps,\n",
    "            save_total_limit = 1, #only save the last 5 checkpoints\n",
    "            fp16=True,\n",
    "            learning_rate = 5e-5,  # 5e-5 is the default\n",
    "            logging_steps = 10, #50_000\n",
    "            evaluation_strategy = 'steps',\n",
    "            # evaluate_during_training = True,\n",
    "            eval_steps = 10\n",
    "            \n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args = training_args,\n",
    "            # data_collator=data_collator,\n",
    "            train_dataset=dataset_train,\n",
    "            eval_dataset=dataset_validation,\n",
    "            compute_metrics = compute_metrics\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # trainer.train(resume_from_checkpoint=True)\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv('ASND_results.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b7f13-c4fa-4355-9192-11d71fbab952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382f88d-15fb-48d8-8b29-f328f6817a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb4923-7e46-4c22-a4b7-0321fdc9c707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
