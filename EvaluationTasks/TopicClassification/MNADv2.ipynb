{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:12:26.765973: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-12 17:12:26.791231: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-12 17:12:27.154854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/855591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/213898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23401' max='23401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23401/23401 2:38:40, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.715300</td>\n",
       "      <td>0.607891</td>\n",
       "      <td>0.784299</td>\n",
       "      <td>0.668462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.595200</td>\n",
       "      <td>0.560654</td>\n",
       "      <td>0.798245</td>\n",
       "      <td>0.697260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.563200</td>\n",
       "      <td>0.541652</td>\n",
       "      <td>0.803579</td>\n",
       "      <td>0.710050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.512400</td>\n",
       "      <td>0.530050</td>\n",
       "      <td>0.810087</td>\n",
       "      <td>0.719087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.490800</td>\n",
       "      <td>0.525943</td>\n",
       "      <td>0.810082</td>\n",
       "      <td>0.725743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.489200</td>\n",
       "      <td>0.516450</td>\n",
       "      <td>0.812743</td>\n",
       "      <td>0.725677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.533392</td>\n",
       "      <td>0.808970</td>\n",
       "      <td>0.727631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.408600</td>\n",
       "      <td>0.545680</td>\n",
       "      <td>0.808469</td>\n",
       "      <td>0.725988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.532448</td>\n",
       "      <td>0.812476</td>\n",
       "      <td>0.728544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.410600</td>\n",
       "      <td>0.528056</td>\n",
       "      <td>0.813514</td>\n",
       "      <td>0.734117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.566835</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.726989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.567712</td>\n",
       "      <td>0.809026</td>\n",
       "      <td>0.726765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.561789</td>\n",
       "      <td>0.811279</td>\n",
       "      <td>0.731604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.290400</td>\n",
       "      <td>0.625525</td>\n",
       "      <td>0.807474</td>\n",
       "      <td>0.725407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.269200</td>\n",
       "      <td>0.613997</td>\n",
       "      <td>0.806333</td>\n",
       "      <td>0.725749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.631051</td>\n",
       "      <td>0.804627</td>\n",
       "      <td>0.724437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.253800</td>\n",
       "      <td>0.678495</td>\n",
       "      <td>0.803822</td>\n",
       "      <td>0.718633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.212400</td>\n",
       "      <td>0.696343</td>\n",
       "      <td>0.803575</td>\n",
       "      <td>0.720325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.213300</td>\n",
       "      <td>0.694650</td>\n",
       "      <td>0.805753</td>\n",
       "      <td>0.721334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.695162</td>\n",
       "      <td>0.803794</td>\n",
       "      <td>0.721689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.758563</td>\n",
       "      <td>0.802261</td>\n",
       "      <td>0.718487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.762432</td>\n",
       "      <td>0.801737</td>\n",
       "      <td>0.718367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.758106</td>\n",
       "      <td>0.801709</td>\n",
       "      <td>0.719332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/855591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/213898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23401' max='23401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23401/23401 2:38:38, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.704400</td>\n",
       "      <td>0.597834</td>\n",
       "      <td>0.788726</td>\n",
       "      <td>0.672371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.589000</td>\n",
       "      <td>0.555061</td>\n",
       "      <td>0.800391</td>\n",
       "      <td>0.701494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.557900</td>\n",
       "      <td>0.539297</td>\n",
       "      <td>0.803757</td>\n",
       "      <td>0.714249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.504900</td>\n",
       "      <td>0.530882</td>\n",
       "      <td>0.809778</td>\n",
       "      <td>0.720448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.482300</td>\n",
       "      <td>0.521116</td>\n",
       "      <td>0.812228</td>\n",
       "      <td>0.727563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.484400</td>\n",
       "      <td>0.514516</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.726605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.456900</td>\n",
       "      <td>0.526329</td>\n",
       "      <td>0.809802</td>\n",
       "      <td>0.734367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.410700</td>\n",
       "      <td>0.537520</td>\n",
       "      <td>0.811050</td>\n",
       "      <td>0.728391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.531252</td>\n",
       "      <td>0.811639</td>\n",
       "      <td>0.724944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.414200</td>\n",
       "      <td>0.521816</td>\n",
       "      <td>0.814276</td>\n",
       "      <td>0.732429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>0.561159</td>\n",
       "      <td>0.812588</td>\n",
       "      <td>0.728651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.343300</td>\n",
       "      <td>0.558179</td>\n",
       "      <td>0.810657</td>\n",
       "      <td>0.724793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.344100</td>\n",
       "      <td>0.561365</td>\n",
       "      <td>0.811462</td>\n",
       "      <td>0.730084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.611249</td>\n",
       "      <td>0.807352</td>\n",
       "      <td>0.723659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.277600</td>\n",
       "      <td>0.608574</td>\n",
       "      <td>0.807277</td>\n",
       "      <td>0.725246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.278700</td>\n",
       "      <td>0.610233</td>\n",
       "      <td>0.806824</td>\n",
       "      <td>0.723865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.261300</td>\n",
       "      <td>0.660661</td>\n",
       "      <td>0.806006</td>\n",
       "      <td>0.719991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.673391</td>\n",
       "      <td>0.805590</td>\n",
       "      <td>0.717024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.679651</td>\n",
       "      <td>0.806333</td>\n",
       "      <td>0.719411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.678313</td>\n",
       "      <td>0.804238</td>\n",
       "      <td>0.718875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.730654</td>\n",
       "      <td>0.802855</td>\n",
       "      <td>0.715049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.180600</td>\n",
       "      <td>0.735790</td>\n",
       "      <td>0.802640</td>\n",
       "      <td>0.715393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.736103</td>\n",
       "      <td>0.802686</td>\n",
       "      <td>0.717014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/855591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/213898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23401' max='23401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23401/23401 2:39:12, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.704400</td>\n",
       "      <td>0.597834</td>\n",
       "      <td>0.788726</td>\n",
       "      <td>0.672371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.589000</td>\n",
       "      <td>0.555061</td>\n",
       "      <td>0.800391</td>\n",
       "      <td>0.701494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.557900</td>\n",
       "      <td>0.539297</td>\n",
       "      <td>0.803757</td>\n",
       "      <td>0.714249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.504900</td>\n",
       "      <td>0.530882</td>\n",
       "      <td>0.809778</td>\n",
       "      <td>0.720448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.482300</td>\n",
       "      <td>0.521116</td>\n",
       "      <td>0.812228</td>\n",
       "      <td>0.727563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.484400</td>\n",
       "      <td>0.514516</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.726605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.456900</td>\n",
       "      <td>0.526329</td>\n",
       "      <td>0.809802</td>\n",
       "      <td>0.734367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.410700</td>\n",
       "      <td>0.537520</td>\n",
       "      <td>0.811050</td>\n",
       "      <td>0.728391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.531252</td>\n",
       "      <td>0.811639</td>\n",
       "      <td>0.724944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.414200</td>\n",
       "      <td>0.521816</td>\n",
       "      <td>0.814276</td>\n",
       "      <td>0.732429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>0.561159</td>\n",
       "      <td>0.812588</td>\n",
       "      <td>0.728651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.343300</td>\n",
       "      <td>0.558179</td>\n",
       "      <td>0.810657</td>\n",
       "      <td>0.724793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.344100</td>\n",
       "      <td>0.561365</td>\n",
       "      <td>0.811462</td>\n",
       "      <td>0.730084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.611249</td>\n",
       "      <td>0.807352</td>\n",
       "      <td>0.723659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.277600</td>\n",
       "      <td>0.608574</td>\n",
       "      <td>0.807277</td>\n",
       "      <td>0.725246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.278700</td>\n",
       "      <td>0.610233</td>\n",
       "      <td>0.806824</td>\n",
       "      <td>0.723865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.261300</td>\n",
       "      <td>0.660661</td>\n",
       "      <td>0.806006</td>\n",
       "      <td>0.719991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.673391</td>\n",
       "      <td>0.805590</td>\n",
       "      <td>0.717024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.679651</td>\n",
       "      <td>0.806333</td>\n",
       "      <td>0.719411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.678313</td>\n",
       "      <td>0.804238</td>\n",
       "      <td>0.718875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.730654</td>\n",
       "      <td>0.802855</td>\n",
       "      <td>0.715049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.180600</td>\n",
       "      <td>0.735790</td>\n",
       "      <td>0.802640</td>\n",
       "      <td>0.715393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.736103</td>\n",
       "      <td>0.802686</td>\n",
       "      <td>0.717014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/855591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/213898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23401' max='23401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23401/23401 2:38:01, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.718800</td>\n",
       "      <td>0.614298</td>\n",
       "      <td>0.780779</td>\n",
       "      <td>0.654680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.611700</td>\n",
       "      <td>0.582437</td>\n",
       "      <td>0.787689</td>\n",
       "      <td>0.679710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.580600</td>\n",
       "      <td>0.557771</td>\n",
       "      <td>0.797497</td>\n",
       "      <td>0.694344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.533900</td>\n",
       "      <td>0.543953</td>\n",
       "      <td>0.803374</td>\n",
       "      <td>0.706749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.514200</td>\n",
       "      <td>0.538505</td>\n",
       "      <td>0.806211</td>\n",
       "      <td>0.713974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>0.529191</td>\n",
       "      <td>0.807212</td>\n",
       "      <td>0.718118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.485600</td>\n",
       "      <td>0.525138</td>\n",
       "      <td>0.810092</td>\n",
       "      <td>0.727541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.442100</td>\n",
       "      <td>0.532561</td>\n",
       "      <td>0.809362</td>\n",
       "      <td>0.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.444300</td>\n",
       "      <td>0.530362</td>\n",
       "      <td>0.810124</td>\n",
       "      <td>0.721733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.443200</td>\n",
       "      <td>0.523239</td>\n",
       "      <td>0.811663</td>\n",
       "      <td>0.729814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.548136</td>\n",
       "      <td>0.810840</td>\n",
       "      <td>0.726008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>0.551240</td>\n",
       "      <td>0.808605</td>\n",
       "      <td>0.725627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>0.545280</td>\n",
       "      <td>0.810690</td>\n",
       "      <td>0.731307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.583410</td>\n",
       "      <td>0.808465</td>\n",
       "      <td>0.726680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.587123</td>\n",
       "      <td>0.806235</td>\n",
       "      <td>0.725546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.309100</td>\n",
       "      <td>0.591847</td>\n",
       "      <td>0.806296</td>\n",
       "      <td>0.724616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.292600</td>\n",
       "      <td>0.622597</td>\n",
       "      <td>0.806520</td>\n",
       "      <td>0.725475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.633249</td>\n",
       "      <td>0.805384</td>\n",
       "      <td>0.723156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.641489</td>\n",
       "      <td>0.804037</td>\n",
       "      <td>0.722716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.638824</td>\n",
       "      <td>0.804075</td>\n",
       "      <td>0.722168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.682620</td>\n",
       "      <td>0.802368</td>\n",
       "      <td>0.719797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>0.685640</td>\n",
       "      <td>0.802981</td>\n",
       "      <td>0.719759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.209900</td>\n",
       "      <td>0.685230</td>\n",
       "      <td>0.802756</td>\n",
       "      <td>0.721768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/855591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/213898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23401' max='23401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23401/23401 2:37:54, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.718800</td>\n",
       "      <td>0.614298</td>\n",
       "      <td>0.780779</td>\n",
       "      <td>0.654680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.611700</td>\n",
       "      <td>0.582437</td>\n",
       "      <td>0.787689</td>\n",
       "      <td>0.679710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.580600</td>\n",
       "      <td>0.557771</td>\n",
       "      <td>0.797497</td>\n",
       "      <td>0.694344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.533900</td>\n",
       "      <td>0.543953</td>\n",
       "      <td>0.803374</td>\n",
       "      <td>0.706749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.514200</td>\n",
       "      <td>0.538505</td>\n",
       "      <td>0.806211</td>\n",
       "      <td>0.713974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>0.529191</td>\n",
       "      <td>0.807212</td>\n",
       "      <td>0.718118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.485600</td>\n",
       "      <td>0.525138</td>\n",
       "      <td>0.810092</td>\n",
       "      <td>0.727541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.442100</td>\n",
       "      <td>0.532561</td>\n",
       "      <td>0.809362</td>\n",
       "      <td>0.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.444300</td>\n",
       "      <td>0.530362</td>\n",
       "      <td>0.810124</td>\n",
       "      <td>0.721733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.443200</td>\n",
       "      <td>0.523239</td>\n",
       "      <td>0.811663</td>\n",
       "      <td>0.729814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.548136</td>\n",
       "      <td>0.810840</td>\n",
       "      <td>0.726008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>0.551240</td>\n",
       "      <td>0.808605</td>\n",
       "      <td>0.725627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>0.545280</td>\n",
       "      <td>0.810690</td>\n",
       "      <td>0.731307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.583410</td>\n",
       "      <td>0.808465</td>\n",
       "      <td>0.726680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.587123</td>\n",
       "      <td>0.806235</td>\n",
       "      <td>0.725546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.309100</td>\n",
       "      <td>0.591847</td>\n",
       "      <td>0.806296</td>\n",
       "      <td>0.724616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.292600</td>\n",
       "      <td>0.622597</td>\n",
       "      <td>0.806520</td>\n",
       "      <td>0.725475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.633249</td>\n",
       "      <td>0.805384</td>\n",
       "      <td>0.723156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.641489</td>\n",
       "      <td>0.804037</td>\n",
       "      <td>0.722716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.638824</td>\n",
       "      <td>0.804075</td>\n",
       "      <td>0.722168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.682620</td>\n",
       "      <td>0.802368</td>\n",
       "      <td>0.719797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>0.685640</td>\n",
       "      <td>0.802981</td>\n",
       "      <td>0.719759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.209900</td>\n",
       "      <td>0.685230</td>\n",
       "      <td>0.802756</td>\n",
       "      <td>0.721768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/855591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/213898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23401' max='23401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23401/23401 2:39:10, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.718800</td>\n",
       "      <td>0.614298</td>\n",
       "      <td>0.780779</td>\n",
       "      <td>0.654680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.611700</td>\n",
       "      <td>0.582437</td>\n",
       "      <td>0.787689</td>\n",
       "      <td>0.679710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.580600</td>\n",
       "      <td>0.557771</td>\n",
       "      <td>0.797497</td>\n",
       "      <td>0.694344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.533900</td>\n",
       "      <td>0.543953</td>\n",
       "      <td>0.803374</td>\n",
       "      <td>0.706749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.514200</td>\n",
       "      <td>0.538505</td>\n",
       "      <td>0.806211</td>\n",
       "      <td>0.713974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>0.529191</td>\n",
       "      <td>0.807212</td>\n",
       "      <td>0.718118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.485600</td>\n",
       "      <td>0.525138</td>\n",
       "      <td>0.810092</td>\n",
       "      <td>0.727541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.442100</td>\n",
       "      <td>0.532561</td>\n",
       "      <td>0.809362</td>\n",
       "      <td>0.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.444300</td>\n",
       "      <td>0.530362</td>\n",
       "      <td>0.810124</td>\n",
       "      <td>0.721733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.443200</td>\n",
       "      <td>0.523239</td>\n",
       "      <td>0.811663</td>\n",
       "      <td>0.729814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.548136</td>\n",
       "      <td>0.810840</td>\n",
       "      <td>0.726008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>0.551240</td>\n",
       "      <td>0.808605</td>\n",
       "      <td>0.725627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>0.545280</td>\n",
       "      <td>0.810690</td>\n",
       "      <td>0.731307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.583410</td>\n",
       "      <td>0.808465</td>\n",
       "      <td>0.726680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.587123</td>\n",
       "      <td>0.806235</td>\n",
       "      <td>0.725546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.309100</td>\n",
       "      <td>0.591847</td>\n",
       "      <td>0.806296</td>\n",
       "      <td>0.724616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.292600</td>\n",
       "      <td>0.622597</td>\n",
       "      <td>0.806520</td>\n",
       "      <td>0.725475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.633249</td>\n",
       "      <td>0.805384</td>\n",
       "      <td>0.723156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.641489</td>\n",
       "      <td>0.804037</td>\n",
       "      <td>0.722716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.638824</td>\n",
       "      <td>0.804075</td>\n",
       "      <td>0.722168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.682620</td>\n",
       "      <td>0.802368</td>\n",
       "      <td>0.719797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>0.685640</td>\n",
       "      <td>0.802981</td>\n",
       "      <td>0.719759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.209900</td>\n",
       "      <td>0.685230</td>\n",
       "      <td>0.802756</td>\n",
       "      <td>0.721768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/855591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/213898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23401' max='23401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23401/23401 2:32:22, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.590281</td>\n",
       "      <td>0.791298</td>\n",
       "      <td>0.682653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.579200</td>\n",
       "      <td>0.543536</td>\n",
       "      <td>0.804411</td>\n",
       "      <td>0.709508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.548700</td>\n",
       "      <td>0.527571</td>\n",
       "      <td>0.808077</td>\n",
       "      <td>0.725470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.492900</td>\n",
       "      <td>0.518878</td>\n",
       "      <td>0.812939</td>\n",
       "      <td>0.732112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.470200</td>\n",
       "      <td>0.512700</td>\n",
       "      <td>0.815169</td>\n",
       "      <td>0.740451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.469200</td>\n",
       "      <td>0.505807</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.740602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.436600</td>\n",
       "      <td>0.524987</td>\n",
       "      <td>0.814295</td>\n",
       "      <td>0.741304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>0.530692</td>\n",
       "      <td>0.814052</td>\n",
       "      <td>0.742296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.383300</td>\n",
       "      <td>0.528067</td>\n",
       "      <td>0.814659</td>\n",
       "      <td>0.741613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.816244</td>\n",
       "      <td>0.746100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.574050</td>\n",
       "      <td>0.812359</td>\n",
       "      <td>0.738375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>0.575540</td>\n",
       "      <td>0.810676</td>\n",
       "      <td>0.735251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.304400</td>\n",
       "      <td>0.575468</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.739928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.635984</td>\n",
       "      <td>0.808128</td>\n",
       "      <td>0.735195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.636506</td>\n",
       "      <td>0.808498</td>\n",
       "      <td>0.737583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.640887</td>\n",
       "      <td>0.806641</td>\n",
       "      <td>0.738227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>0.698250</td>\n",
       "      <td>0.806609</td>\n",
       "      <td>0.733085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.711740</td>\n",
       "      <td>0.804318</td>\n",
       "      <td>0.732881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.720162</td>\n",
       "      <td>0.805524</td>\n",
       "      <td>0.734154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>0.718822</td>\n",
       "      <td>0.804145</td>\n",
       "      <td>0.733950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>0.774454</td>\n",
       "      <td>0.803626</td>\n",
       "      <td>0.732290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.780252</td>\n",
       "      <td>0.803589</td>\n",
       "      <td>0.733366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.781865</td>\n",
       "      <td>0.804019</td>\n",
       "      <td>0.733692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/855591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/213898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23401' max='23401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23401/23401 2:32:44, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.590281</td>\n",
       "      <td>0.791298</td>\n",
       "      <td>0.682653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.579200</td>\n",
       "      <td>0.543536</td>\n",
       "      <td>0.804411</td>\n",
       "      <td>0.709508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.548700</td>\n",
       "      <td>0.527571</td>\n",
       "      <td>0.808077</td>\n",
       "      <td>0.725470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.492900</td>\n",
       "      <td>0.518878</td>\n",
       "      <td>0.812939</td>\n",
       "      <td>0.732112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.470200</td>\n",
       "      <td>0.512700</td>\n",
       "      <td>0.815169</td>\n",
       "      <td>0.740451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.469200</td>\n",
       "      <td>0.505807</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.740602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.436600</td>\n",
       "      <td>0.524987</td>\n",
       "      <td>0.814295</td>\n",
       "      <td>0.741304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>0.530692</td>\n",
       "      <td>0.814052</td>\n",
       "      <td>0.742296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.383300</td>\n",
       "      <td>0.528067</td>\n",
       "      <td>0.814659</td>\n",
       "      <td>0.741613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.816244</td>\n",
       "      <td>0.746100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.574050</td>\n",
       "      <td>0.812359</td>\n",
       "      <td>0.738375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>0.575540</td>\n",
       "      <td>0.810676</td>\n",
       "      <td>0.735251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.304400</td>\n",
       "      <td>0.575468</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.739928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.635984</td>\n",
       "      <td>0.808128</td>\n",
       "      <td>0.735195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.636506</td>\n",
       "      <td>0.808498</td>\n",
       "      <td>0.737583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.640887</td>\n",
       "      <td>0.806641</td>\n",
       "      <td>0.738227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>0.698250</td>\n",
       "      <td>0.806609</td>\n",
       "      <td>0.733085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.711740</td>\n",
       "      <td>0.804318</td>\n",
       "      <td>0.732881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.720162</td>\n",
       "      <td>0.805524</td>\n",
       "      <td>0.734154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>0.718822</td>\n",
       "      <td>0.804145</td>\n",
       "      <td>0.733950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>0.774454</td>\n",
       "      <td>0.803626</td>\n",
       "      <td>0.732290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.780252</td>\n",
       "      <td>0.803589</td>\n",
       "      <td>0.733366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.781865</td>\n",
       "      <td>0.804019</td>\n",
       "      <td>0.733692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/855591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/213898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23401' max='23401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23401/23401 2:32:45, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.590281</td>\n",
       "      <td>0.791298</td>\n",
       "      <td>0.682653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.579200</td>\n",
       "      <td>0.543536</td>\n",
       "      <td>0.804411</td>\n",
       "      <td>0.709508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.548700</td>\n",
       "      <td>0.527571</td>\n",
       "      <td>0.808077</td>\n",
       "      <td>0.725470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.492900</td>\n",
       "      <td>0.518878</td>\n",
       "      <td>0.812939</td>\n",
       "      <td>0.732112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.470200</td>\n",
       "      <td>0.512700</td>\n",
       "      <td>0.815169</td>\n",
       "      <td>0.740451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.469200</td>\n",
       "      <td>0.505807</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.740602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.436600</td>\n",
       "      <td>0.524987</td>\n",
       "      <td>0.814295</td>\n",
       "      <td>0.741304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>0.530692</td>\n",
       "      <td>0.814052</td>\n",
       "      <td>0.742296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.383300</td>\n",
       "      <td>0.528067</td>\n",
       "      <td>0.814659</td>\n",
       "      <td>0.741613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.816244</td>\n",
       "      <td>0.746100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.574050</td>\n",
       "      <td>0.812359</td>\n",
       "      <td>0.738375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>0.575540</td>\n",
       "      <td>0.810676</td>\n",
       "      <td>0.735251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.304400</td>\n",
       "      <td>0.575468</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.739928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.635984</td>\n",
       "      <td>0.808128</td>\n",
       "      <td>0.735195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.636506</td>\n",
       "      <td>0.808498</td>\n",
       "      <td>0.737583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.640887</td>\n",
       "      <td>0.806641</td>\n",
       "      <td>0.738227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>0.698250</td>\n",
       "      <td>0.806609</td>\n",
       "      <td>0.733085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.711740</td>\n",
       "      <td>0.804318</td>\n",
       "      <td>0.732881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.720162</td>\n",
       "      <td>0.805524</td>\n",
       "      <td>0.734154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>0.718822</td>\n",
       "      <td>0.804145</td>\n",
       "      <td>0.733950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>0.774454</td>\n",
       "      <td>0.803626</td>\n",
       "      <td>0.732290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.780252</td>\n",
       "      <td>0.803589</td>\n",
       "      <td>0.733366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.781865</td>\n",
       "      <td>0.804019</td>\n",
       "      <td>0.733692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faisalq/bert-base-arabic-bbpe</td>\n",
       "      <td>0.816244</td>\n",
       "      <td>0.746100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faisalq/bert-base-arabic-bbpe</td>\n",
       "      <td>0.816244</td>\n",
       "      <td>0.746100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>faisalq/bert-base-arabic-bbpe</td>\n",
       "      <td>0.816244</td>\n",
       "      <td>0.746100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>faisalq/bert-base-arabic-senpiece</td>\n",
       "      <td>0.810690</td>\n",
       "      <td>0.731307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>faisalq/bert-base-arabic-senpiece</td>\n",
       "      <td>0.810690</td>\n",
       "      <td>0.731307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>faisalq/bert-base-arabic-senpiece</td>\n",
       "      <td>0.810690</td>\n",
       "      <td>0.731307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/bert-base-arabic-wordpiece</td>\n",
       "      <td>0.809802</td>\n",
       "      <td>0.734367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>faisalq/bert-base-arabic-wordpiece</td>\n",
       "      <td>0.809802</td>\n",
       "      <td>0.734367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  Accuracy        F1\n",
       "0       faisalq/bert-base-arabic-bbpe  0.816244  0.746100\n",
       "1       faisalq/bert-base-arabic-bbpe  0.816244  0.746100\n",
       "2       faisalq/bert-base-arabic-bbpe  0.816244  0.746100\n",
       "3   faisalq/bert-base-arabic-senpiece  0.810690  0.731307\n",
       "4   faisalq/bert-base-arabic-senpiece  0.810690  0.731307\n",
       "5   faisalq/bert-base-arabic-senpiece  0.810690  0.731307\n",
       "6  faisalq/bert-base-arabic-wordpiece  0.809802  0.734367\n",
       "7  faisalq/bert-base-arabic-wordpiece  0.809802  0.734367"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell-1  \n",
    "#load and clean the data (removing diacritics and unwanted text)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "log_file = 'MNADv2.txt'\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "df = pd.read_csv('MNADv2/MNADv2.csv')\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "\n",
    "df['Category'] = df['Category'].astype('category')\n",
    "# display(dfc['meter'].unique())\n",
    "\n",
    "df['label'] = df['Category'].cat.codes #assign cat_value for each meter type\n",
    "# dftrain, dftest = train_test_split(df, test_size=0.20, random_state=42, stratify=df['label'])\n",
    "# ytrain = dftrain['label'].values.tolist()\n",
    "# ytest = dftest['label'].values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "max_sequence_length = 128\n",
    "train_batch_size = 128\n",
    "classes_num = len(df['Category'].unique())\n",
    "df = df[['Body', 'label']]\n",
    "display(classes_num)\n",
    "# display(len(df))\n",
    "# display(len(dftrain))\n",
    "# display(len(dftest))\n",
    "\n",
    "# dftrain = dftrain[['Body']]\n",
    "# dftest = dftest[['Body']]\n",
    "# df = ''\n",
    "\n",
    "# display(df[:2])\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "models = ['faisalq/bert-base-arabic-wordpiece', 'faisalq/bert-base-arabic-senpiece',\n",
    "          'faisalq/bert-base-arabic-bbpe']\n",
    "\n",
    "\n",
    "for model_name in models:\n",
    "    for i in range(3):\n",
    "        print(f'{model_name}, try:{i}')\n",
    "              \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = BertForSequenceClassification.from_pretrained(model_name,\n",
    "                                                              num_labels=classes_num).to('cuda')                                                 \n",
    "        dataset_train = ds['train']\n",
    "        dataset_validation = ds['test']                                                     \n",
    "        \n",
    "      \n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            return tokenizer(examples['Body'], truncation=True, padding=\"max_length\",\n",
    "                            max_length=max_sequence_length)\n",
    "        \n",
    "        \n",
    "        dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "        dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "        \n",
    "       \n",
    "        \n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)    \n",
    "            acc = accuracy_score(labels, predictions)        \n",
    "            f1 = f1_score(labels, predictions, average='macro')   \n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{model_name},{acc},{f1}\\n')\n",
    "            return {'accuracy': acc, 'f1_score': f1}\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        epochs = 7\n",
    "        save_steps = 10000 #save checkpoint every 10000 steps\n",
    "        batch_size = 256\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = 'bert/',\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs = epochs,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            save_steps = save_steps,\n",
    "            save_total_limit = 1, #only save the last 5 checkpoints\n",
    "            fp16=True,\n",
    "            learning_rate = 5e-5,  # 5e-5 is the default\n",
    "            logging_steps = 1000, #50_000\n",
    "            evaluation_strategy = 'steps',\n",
    "            # evaluate_during_training = True,\n",
    "            eval_steps = 1000\n",
    "            \n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args = training_args,\n",
    "            # data_collator=data_collator,\n",
    "            train_dataset=dataset_train,\n",
    "            eval_dataset=dataset_validation,\n",
    "            compute_metrics = compute_metrics\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # trainer.train(resume_from_checkpoint=True)\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results.to_csv('MNADv2_results.csv')\n",
    "display(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b7f13-c4fa-4355-9192-11d71fbab952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382f88d-15fb-48d8-8b29-f328f6817a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb4923-7e46-4c22-a4b7-0321fdc9c707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
