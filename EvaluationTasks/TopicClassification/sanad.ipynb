{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 01:11:36.336194: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-12 01:11:36.462126: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-12 01:11:37.035542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "45500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "36400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أعلن اتحاد كتاب وأدباء الإمارات فرع أبوظبي برنامج نشاطه خلال الأسبوع الجاري، وستكون البداية اليوم حيث يحتفي بيوم الشعر العالمي بأمسية شعرية موسيقية يتناوب فيها كل من الشاعرات زينب عامر الشاعرة والإعلامية الإماراتية صاحبة المجموعة الشعرية المطبوعة (ارتباك الشمس)؛ وشيخة المطيري الشاعرة الإماراتية صاحبة الديوانين المطبوعين (مرسى الوداد) و(للحنين بقية) فضلاً عن عشرات المشاركات في أمسيات ومهرجانات وتظاهرات ثقافية داخل الإمارات وخارجها؛ وفاطمة المعمري الشاعرة والكاتبة الإماراتية عضو اتحاد كتاب وأدباء الإمارات، وعضو رابطة أديبات الإمارات . وتأتي القراءات الشعرية على خلفية موسيقية حية تقدمها خريجة بيت العود العربي في مصر العازفة شيرين التهامي .تقام الأمسية في قاعة عبدالله عمران في مقر الاتحاد في معسكر آل نهيان في أبوظبي عند السابعة والنصف مساء .وفي مقره في المسرح الوطني في أبوظبي يستضيف الاتحاد عند السابعة والنصف مساء الاثنين الشاعر أحمد العسم، في أجزاء من نص طويل له بعنوان \"أمينة\"، وسيوقع كتابه \"سوالف شوك\" وهو مجموعة نصوص بالمحكية .مساء الثلاثاء وبالتعاون مع هيئة أبوظبي للسياحة والثقافة ي...</td>\n",
       "      <td>Culture</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>بتوجيهات سمو الشيخ منصور بن زايد آل نهيان نائب رئيس مجلس الوزراء وزير شؤون الرئاسة شارك الأرشيف الوطني في الدورة ال49 لمعرض القاهرة الدولي للكتاب والتي افتتحتها أمس الأول إيناس عبد الدايم وزيرة الثقافة المصرية والدكتور عز الدين ميهوبي وزير الثقافة الجزائري وتستمر حتي العاشر من فبراير المقبل.وأكد حمد عبدالرحمن المدفع الأمين العام للمجلس الأعلى للاتحاد رئيس مجلس إدارة الأرشيف الوطني أهمية هذه المشاركة التي تتزامن مع عام زايد، حيث جاءت التوجيهات بأهمية نشر أهداف عام زايد الخير في أهم التظاهرات الثقافية في العالم العربي وليكون معرض القاهرة منصة هامة لتنفيذ مبادرات الأرشيف الوطني في عام زايد والتي تتضمن العديد من الفعاليات والمشاريع التي تؤرخ وتوثق مآثر ومناقب المغفور له الشيخ زايد بن سلطان آل نهيان، طيب الله ثراه. وقال محمد أحمد المر نائب رئيس مجلس إدارة الأرشيف الوطني إن الأرشيف الوطني حريص على المشاركة البناءة بمعرض القاهرة الدولي للكتاب؛ بوصفه تظاهرة ثقافية سنوية للمثقفين والباحثين والقراء، للتعريف بتاريخ دولة الإمارات ومؤسسها -المغفور له بإذن الله - الشيخ زايد بن سلطان آل نهيان، لا...</td>\n",
       "      <td>Culture</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>يقام على هامش الأيام معرض ذاكرة الأيام الذي درجت دائرة الثقافة والإعلام على تنظيمه بمصاحبة الأيام وهو معرض للصور الفوتوغرافية بعدسة المصور الفوتوغرافي محمود بنيان، وقد وثق فيه هذه السنة للدورة الماضية من الأيام، وقدم فيه 26 صورة لثلاثة عشر عرضاً بواقع صورتين لكل مسرحية، حرب النعل والرهان وقرموشة والسلوقي وعار الوقار وأصايل وحلوج . . إلخ، ويسعى المعرض إلى إبراز الديكور والسينوغرافيا والحركة على خشبة المسرح، وذلك باختيار زوايا عدة للصورة .ويقول محمود بنيان عن المعرض إنه يمثل ذاكرة حقيقية للأيام، نريد منها أن نوثق اللقطات الجميلة في هذه التظاهرة الوطنية الكبرى، ويمكن للصورة أن تعرف المشاهد على التطور الذي يحصل من مهرجان لآخر، كما أن اختيار اللقطات البارزة للفنانين الممثلين يشكل تاريخاً لهم، وذكرى جميلة تقول للمشاهد بأن هذا المسرحي المبدع مر من هنا، وأن الأيام كانت محطة بارزة في تاريخه .</td>\n",
       "      <td>Culture</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text   \n",
       "0  أعلن اتحاد كتاب وأدباء الإمارات فرع أبوظبي برنامج نشاطه خلال الأسبوع الجاري، وستكون البداية اليوم حيث يحتفي بيوم الشعر العالمي بأمسية شعرية موسيقية يتناوب فيها كل من الشاعرات زينب عامر الشاعرة والإعلامية الإماراتية صاحبة المجموعة الشعرية المطبوعة (ارتباك الشمس)؛ وشيخة المطيري الشاعرة الإماراتية صاحبة الديوانين المطبوعين (مرسى الوداد) و(للحنين بقية) فضلاً عن عشرات المشاركات في أمسيات ومهرجانات وتظاهرات ثقافية داخل الإمارات وخارجها؛ وفاطمة المعمري الشاعرة والكاتبة الإماراتية عضو اتحاد كتاب وأدباء الإمارات، وعضو رابطة أديبات الإمارات . وتأتي القراءات الشعرية على خلفية موسيقية حية تقدمها خريجة بيت العود العربي في مصر العازفة شيرين التهامي .تقام الأمسية في قاعة عبدالله عمران في مقر الاتحاد في معسكر آل نهيان في أبوظبي عند السابعة والنصف مساء .وفي مقره في المسرح الوطني في أبوظبي يستضيف الاتحاد عند السابعة والنصف مساء الاثنين الشاعر أحمد العسم، في أجزاء من نص طويل له بعنوان \"أمينة\"، وسيوقع كتابه \"سوالف شوك\" وهو مجموعة نصوص بالمحكية .مساء الثلاثاء وبالتعاون مع هيئة أبوظبي للسياحة والثقافة ي...  \\\n",
       "1  بتوجيهات سمو الشيخ منصور بن زايد آل نهيان نائب رئيس مجلس الوزراء وزير شؤون الرئاسة شارك الأرشيف الوطني في الدورة ال49 لمعرض القاهرة الدولي للكتاب والتي افتتحتها أمس الأول إيناس عبد الدايم وزيرة الثقافة المصرية والدكتور عز الدين ميهوبي وزير الثقافة الجزائري وتستمر حتي العاشر من فبراير المقبل.وأكد حمد عبدالرحمن المدفع الأمين العام للمجلس الأعلى للاتحاد رئيس مجلس إدارة الأرشيف الوطني أهمية هذه المشاركة التي تتزامن مع عام زايد، حيث جاءت التوجيهات بأهمية نشر أهداف عام زايد الخير في أهم التظاهرات الثقافية في العالم العربي وليكون معرض القاهرة منصة هامة لتنفيذ مبادرات الأرشيف الوطني في عام زايد والتي تتضمن العديد من الفعاليات والمشاريع التي تؤرخ وتوثق مآثر ومناقب المغفور له الشيخ زايد بن سلطان آل نهيان، طيب الله ثراه. وقال محمد أحمد المر نائب رئيس مجلس إدارة الأرشيف الوطني إن الأرشيف الوطني حريص على المشاركة البناءة بمعرض القاهرة الدولي للكتاب؛ بوصفه تظاهرة ثقافية سنوية للمثقفين والباحثين والقراء، للتعريف بتاريخ دولة الإمارات ومؤسسها -المغفور له بإذن الله - الشيخ زايد بن سلطان آل نهيان، لا...   \n",
       "2                                                                                                                                                                                                               يقام على هامش الأيام معرض ذاكرة الأيام الذي درجت دائرة الثقافة والإعلام على تنظيمه بمصاحبة الأيام وهو معرض للصور الفوتوغرافية بعدسة المصور الفوتوغرافي محمود بنيان، وقد وثق فيه هذه السنة للدورة الماضية من الأيام، وقدم فيه 26 صورة لثلاثة عشر عرضاً بواقع صورتين لكل مسرحية، حرب النعل والرهان وقرموشة والسلوقي وعار الوقار وأصايل وحلوج . . إلخ، ويسعى المعرض إلى إبراز الديكور والسينوغرافيا والحركة على خشبة المسرح، وذلك باختيار زوايا عدة للصورة .ويقول محمود بنيان عن المعرض إنه يمثل ذاكرة حقيقية للأيام، نريد منها أن نوثق اللقطات الجميلة في هذه التظاهرة الوطنية الكبرى، ويمكن للصورة أن تعرف المشاهد على التطور الذي يحصل من مهرجان لآخر، كما أن اختيار اللقطات البارزة للفنانين الممثلين يشكل تاريخاً لهم، وذكرى جميلة تقول للمشاهد بأن هذا المسرحي المبدع مر من هنا، وأن الأيام كانت محطة بارزة في تاريخه .   \n",
       "\n",
       "  Category  label  \n",
       "0  Culture      0  \n",
       "1  Culture      0  \n",
       "2  Culture      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell-1  \n",
    "#load and clean the data (removing diacritics and unwanted text)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "log_file = 'SANAD.txt'\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "df = pd.read_csv('sanad/sanad.csv')\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "df['Category'] = df['Category'].astype('category')\n",
    "# display(dfc['meter'].unique())\n",
    "\n",
    "df['label'] = df['Category'].cat.codes #assign cat_value for each meter type\n",
    "dftrain, dftest = train_test_split(df, test_size=0.20, random_state=42, stratify=df['label'])\n",
    "ytrain = dftrain['label'].values.tolist()\n",
    "ytest = dftest['label'].values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "max_sequence_length = 128\n",
    "train_batch_size = 128\n",
    "classes_num = len(df['Category'].unique())\n",
    "\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "display(len(dftrain))\n",
    "display(len(dftest))\n",
    "df['Category'].unique()\n",
    "display(df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd261fd0-0b55-46b6-8f5a-67f213baeb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3575' max='3575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3575/3575 18:25, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.209900</td>\n",
       "      <td>0.071075</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.978604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.065352</td>\n",
       "      <td>0.981209</td>\n",
       "      <td>0.981227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.083161</td>\n",
       "      <td>0.980549</td>\n",
       "      <td>0.980502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.082186</td>\n",
       "      <td>0.983736</td>\n",
       "      <td>0.983728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.087516</td>\n",
       "      <td>0.984176</td>\n",
       "      <td>0.984184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.094298</td>\n",
       "      <td>0.983626</td>\n",
       "      <td>0.983643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.105653</td>\n",
       "      <td>0.981758</td>\n",
       "      <td>0.981758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.112045</td>\n",
       "      <td>0.983077</td>\n",
       "      <td>0.983064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.102031</td>\n",
       "      <td>0.983077</td>\n",
       "      <td>0.983066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.100102</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.102338</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.108320</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>0.984292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.112884</td>\n",
       "      <td>0.984066</td>\n",
       "      <td>0.984071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.111452</td>\n",
       "      <td>0.984505</td>\n",
       "      <td>0.984523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.108159</td>\n",
       "      <td>0.985604</td>\n",
       "      <td>0.985603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109188</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.112102</td>\n",
       "      <td>0.985495</td>\n",
       "      <td>0.985499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.113295</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.113737</td>\n",
       "      <td>0.985604</td>\n",
       "      <td>0.985605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.114396</td>\n",
       "      <td>0.985604</td>\n",
       "      <td>0.985605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.114781</td>\n",
       "      <td>0.985604</td>\n",
       "      <td>0.985605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.115089</td>\n",
       "      <td>0.985495</td>\n",
       "      <td>0.985495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.115407</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.115597</td>\n",
       "      <td>0.985495</td>\n",
       "      <td>0.985493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.115649</td>\n",
       "      <td>0.985495</td>\n",
       "      <td>0.985493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3575' max='3575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3575/3575 18:26, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.204400</td>\n",
       "      <td>0.070005</td>\n",
       "      <td>0.978462</td>\n",
       "      <td>0.978491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.059508</td>\n",
       "      <td>0.982747</td>\n",
       "      <td>0.982741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.068780</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.982286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.091507</td>\n",
       "      <td>0.979231</td>\n",
       "      <td>0.979240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.083624</td>\n",
       "      <td>0.983626</td>\n",
       "      <td>0.983636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.082323</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.085823</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>0.986041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.100972</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.983953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.102799</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.099809</td>\n",
       "      <td>0.985934</td>\n",
       "      <td>0.985930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.100294</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.103376</td>\n",
       "      <td>0.985934</td>\n",
       "      <td>0.985933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.113396</td>\n",
       "      <td>0.984066</td>\n",
       "      <td>0.984065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.114508</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>0.984283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.117293</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.113571</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.112607</td>\n",
       "      <td>0.985495</td>\n",
       "      <td>0.985489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.117340</td>\n",
       "      <td>0.984505</td>\n",
       "      <td>0.984501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.117134</td>\n",
       "      <td>0.985275</td>\n",
       "      <td>0.985270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.118356</td>\n",
       "      <td>0.985165</td>\n",
       "      <td>0.985159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.118264</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.119040</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.119461</td>\n",
       "      <td>0.985495</td>\n",
       "      <td>0.985490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.118931</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.119068</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3575' max='3575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3575/3575 18:27, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.204400</td>\n",
       "      <td>0.070005</td>\n",
       "      <td>0.978462</td>\n",
       "      <td>0.978491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.059508</td>\n",
       "      <td>0.982747</td>\n",
       "      <td>0.982741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.068780</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.982286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.091507</td>\n",
       "      <td>0.979231</td>\n",
       "      <td>0.979240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.083624</td>\n",
       "      <td>0.983626</td>\n",
       "      <td>0.983636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.082323</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.085823</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>0.986041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.100972</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.983953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.102799</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.099809</td>\n",
       "      <td>0.985934</td>\n",
       "      <td>0.985930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.100294</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.103376</td>\n",
       "      <td>0.985934</td>\n",
       "      <td>0.985933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.113396</td>\n",
       "      <td>0.984066</td>\n",
       "      <td>0.984065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.114508</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>0.984283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.117293</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.113571</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.112607</td>\n",
       "      <td>0.985495</td>\n",
       "      <td>0.985489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.117340</td>\n",
       "      <td>0.984505</td>\n",
       "      <td>0.984501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.117134</td>\n",
       "      <td>0.985275</td>\n",
       "      <td>0.985270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.118356</td>\n",
       "      <td>0.985165</td>\n",
       "      <td>0.985159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.118264</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.119040</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.119461</td>\n",
       "      <td>0.985495</td>\n",
       "      <td>0.985490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.118931</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.119068</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3575' max='3575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3575/3575 18:26, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.061686</td>\n",
       "      <td>0.982088</td>\n",
       "      <td>0.982115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.056259</td>\n",
       "      <td>0.984176</td>\n",
       "      <td>0.984168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.061038</td>\n",
       "      <td>0.983626</td>\n",
       "      <td>0.983621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.064283</td>\n",
       "      <td>0.985165</td>\n",
       "      <td>0.985173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.081959</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.983969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.091481</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.982296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.089528</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.983944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.093920</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.103956</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>0.984294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.099991</td>\n",
       "      <td>0.983736</td>\n",
       "      <td>0.983729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.103024</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.102578</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.102407</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.105056</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.107169</td>\n",
       "      <td>0.985055</td>\n",
       "      <td>0.985052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.108659</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.113363</td>\n",
       "      <td>0.983736</td>\n",
       "      <td>0.983750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.116122</td>\n",
       "      <td>0.984066</td>\n",
       "      <td>0.984092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.108410</td>\n",
       "      <td>0.985165</td>\n",
       "      <td>0.985166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.108822</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.110031</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.110663</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.110755</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.111012</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.111050</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3575' max='3575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3575/3575 18:27, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.061686</td>\n",
       "      <td>0.982088</td>\n",
       "      <td>0.982115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.056259</td>\n",
       "      <td>0.984176</td>\n",
       "      <td>0.984168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.061038</td>\n",
       "      <td>0.983626</td>\n",
       "      <td>0.983621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.064283</td>\n",
       "      <td>0.985165</td>\n",
       "      <td>0.985173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.081959</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.983969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.091481</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.982296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.089528</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.983944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.093920</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.103956</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>0.984294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.099991</td>\n",
       "      <td>0.983736</td>\n",
       "      <td>0.983729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.103024</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.102578</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.102407</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.105056</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.107169</td>\n",
       "      <td>0.985055</td>\n",
       "      <td>0.985052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.108659</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.113363</td>\n",
       "      <td>0.983736</td>\n",
       "      <td>0.983750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.116122</td>\n",
       "      <td>0.984066</td>\n",
       "      <td>0.984092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.108410</td>\n",
       "      <td>0.985165</td>\n",
       "      <td>0.985166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.108822</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.110031</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.110663</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.110755</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.111012</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.111050</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3575' max='3575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3575/3575 18:27, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.061686</td>\n",
       "      <td>0.982088</td>\n",
       "      <td>0.982115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.056259</td>\n",
       "      <td>0.984176</td>\n",
       "      <td>0.984168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.061038</td>\n",
       "      <td>0.983626</td>\n",
       "      <td>0.983621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.064283</td>\n",
       "      <td>0.985165</td>\n",
       "      <td>0.985173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.081959</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.983969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.091481</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.982296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.089528</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.983944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.093920</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.103956</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>0.984294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.099991</td>\n",
       "      <td>0.983736</td>\n",
       "      <td>0.983729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.103024</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.102578</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.102407</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.105056</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.107169</td>\n",
       "      <td>0.985055</td>\n",
       "      <td>0.985052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.108659</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.113363</td>\n",
       "      <td>0.983736</td>\n",
       "      <td>0.983750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.116122</td>\n",
       "      <td>0.984066</td>\n",
       "      <td>0.984092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.108410</td>\n",
       "      <td>0.985165</td>\n",
       "      <td>0.985166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.108822</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.110031</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.110663</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.110755</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.111012</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.111050</td>\n",
       "      <td>0.984835</td>\n",
       "      <td>0.984837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3575' max='3575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3575/3575 18:31, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.064695</td>\n",
       "      <td>0.980330</td>\n",
       "      <td>0.980348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.055186</td>\n",
       "      <td>0.983626</td>\n",
       "      <td>0.983636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.065042</td>\n",
       "      <td>0.984066</td>\n",
       "      <td>0.984073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.068867</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.983938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.081378</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.083637</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.083544</td>\n",
       "      <td>0.985604</td>\n",
       "      <td>0.985605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.097840</td>\n",
       "      <td>0.983516</td>\n",
       "      <td>0.983514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.090923</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.087381</td>\n",
       "      <td>0.985604</td>\n",
       "      <td>0.985600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.092170</td>\n",
       "      <td>0.985824</td>\n",
       "      <td>0.985835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.096377</td>\n",
       "      <td>0.985495</td>\n",
       "      <td>0.985503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.095454</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>0.986042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.103495</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.108247</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.118053</td>\n",
       "      <td>0.983187</td>\n",
       "      <td>0.983210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.109536</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.113986</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.104380</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.108613</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109021</td>\n",
       "      <td>0.984505</td>\n",
       "      <td>0.984511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109549</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109603</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109467</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109508</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3575' max='3575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3575/3575 18:24, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.064695</td>\n",
       "      <td>0.980330</td>\n",
       "      <td>0.980348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.055186</td>\n",
       "      <td>0.983626</td>\n",
       "      <td>0.983636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.065042</td>\n",
       "      <td>0.984066</td>\n",
       "      <td>0.984073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.068867</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.983938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.081378</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.083637</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.083544</td>\n",
       "      <td>0.985604</td>\n",
       "      <td>0.985605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.097840</td>\n",
       "      <td>0.983516</td>\n",
       "      <td>0.983514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.090923</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.087381</td>\n",
       "      <td>0.985604</td>\n",
       "      <td>0.985600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.092170</td>\n",
       "      <td>0.985824</td>\n",
       "      <td>0.985835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.096377</td>\n",
       "      <td>0.985495</td>\n",
       "      <td>0.985503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.095454</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>0.986042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.103495</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.108247</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.118053</td>\n",
       "      <td>0.983187</td>\n",
       "      <td>0.983210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.109536</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.113986</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.104380</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.108613</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109021</td>\n",
       "      <td>0.984505</td>\n",
       "      <td>0.984511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109549</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109603</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109467</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109508</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3575' max='3575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3575/3575 18:26, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.064695</td>\n",
       "      <td>0.980330</td>\n",
       "      <td>0.980348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.055186</td>\n",
       "      <td>0.983626</td>\n",
       "      <td>0.983636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.065042</td>\n",
       "      <td>0.984066</td>\n",
       "      <td>0.984073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.068867</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.983938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.081378</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.083637</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.984922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.083544</td>\n",
       "      <td>0.985604</td>\n",
       "      <td>0.985605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.097840</td>\n",
       "      <td>0.983516</td>\n",
       "      <td>0.983514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.090923</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.985377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.087381</td>\n",
       "      <td>0.985604</td>\n",
       "      <td>0.985600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.092170</td>\n",
       "      <td>0.985824</td>\n",
       "      <td>0.985835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.096377</td>\n",
       "      <td>0.985495</td>\n",
       "      <td>0.985503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.095454</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>0.986042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.103495</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.108247</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.118053</td>\n",
       "      <td>0.983187</td>\n",
       "      <td>0.983210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.109536</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.113986</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.104380</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.108613</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109021</td>\n",
       "      <td>0.984505</td>\n",
       "      <td>0.984511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109549</td>\n",
       "      <td>0.984725</td>\n",
       "      <td>0.984731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109603</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109467</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109508</td>\n",
       "      <td>0.984396</td>\n",
       "      <td>0.984400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faisalq/bert-base-arabic-bbpe</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>0.986042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faisalq/bert-base-arabic-bbpe</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>0.986042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>faisalq/bert-base-arabic-bbpe</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>0.986042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>faisalq/bert-base-arabic-senpiece</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>faisalq/bert-base-arabic-senpiece</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>faisalq/bert-base-arabic-senpiece</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/bert-base-arabic-wordpiece</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>0.986041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>faisalq/bert-base-arabic-wordpiece</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>0.986041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  Accuracy        F1\n",
       "0       faisalq/bert-base-arabic-bbpe  0.986044  0.986042\n",
       "1       faisalq/bert-base-arabic-bbpe  0.986044  0.986042\n",
       "2       faisalq/bert-base-arabic-bbpe  0.986044  0.986042\n",
       "3   faisalq/bert-base-arabic-senpiece  0.985714  0.985712\n",
       "4   faisalq/bert-base-arabic-senpiece  0.985714  0.985712\n",
       "5   faisalq/bert-base-arabic-senpiece  0.985714  0.985712\n",
       "6  faisalq/bert-base-arabic-wordpiece  0.986044  0.986041\n",
       "7  faisalq/bert-base-arabic-wordpiece  0.986044  0.986041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "\n",
    "models = ['faisalq/bert-base-arabic-wordpiece', 'faisalq/bert-base-arabic-senpiece',\n",
    "          'faisalq/bert-base-arabic-bbpe']\n",
    "\n",
    "\n",
    "for model_name in models:\n",
    "    for i in range(3):\n",
    "        print(f'{model_name}, try:{i}')\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = BertForSequenceClassification.from_pretrained(model_name,\n",
    "                                                              num_labels=classes_num).to('cuda')                                                 \n",
    "                                                             \n",
    "        \n",
    "        xtrain = tokenizer(\n",
    "            text=dftrain['text'].tolist(),\n",
    "            add_special_tokens=True,\n",
    "            max_length = max_sequence_length,\n",
    "            truncation=True,\n",
    "            padding='max_length', \n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids = False,\n",
    "            return_attention_mask = True,\n",
    "            verbose = True)\n",
    "        \n",
    "        \n",
    "        xtest = tokenizer(\n",
    "            text=dftest['text'].tolist(),\n",
    "            add_special_tokens=True,\n",
    "            max_length = max_sequence_length,\n",
    "            truncation=True,\n",
    "            padding='max_length', \n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids = False,\n",
    "            return_attention_mask = True,\n",
    "            verbose = True)\n",
    "        \n",
    "        \n",
    "        class NewGroupDataset(torch.utils.data.Dataset):\n",
    "            def __init__(self, encodings, labels):\n",
    "                self.encodings = encodings\n",
    "                self.labels = labels\n",
    "        \n",
    "            def __getitem__(self, idx):\n",
    "                item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "                item['label'] = torch.tensor([self.labels[idx]])\n",
    "                return item\n",
    "        \n",
    "            def __len__(self):\n",
    "                return len(self.labels)\n",
    "        \n",
    "        train_ds = NewGroupDataset(xtrain, ytrain)\n",
    "        test_ds = NewGroupDataset(xtest, ytest)\n",
    "        \n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)    \n",
    "            acc = accuracy_score(labels, predictions)        \n",
    "            f1 = f1_score(labels, predictions, average='macro')   \n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{model_name},{acc},{f1}\\n')\n",
    "            return {'accuracy': acc, 'f1_score': f1}\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        epochs = 25\n",
    "        save_steps = 10000 #save checkpoint every 10000 steps\n",
    "        batch_size = 256\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = 'bert_cls/',\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs = epochs,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            save_steps = save_steps,\n",
    "            save_total_limit = 5, #only save the last 5 checkpoints\n",
    "            fp16=True,\n",
    "            learning_rate = 5e-5,  # 5e-5 is the default\n",
    "            logging_steps = 100, #50_000\n",
    "            evaluation_strategy = 'epoch',\n",
    "            # evaluate_during_training = True,\n",
    "            eval_steps = 100\n",
    "            \n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args = training_args,\n",
    "            # data_collator=data_collator,\n",
    "            train_dataset=train_ds,\n",
    "            eval_dataset=test_ds,\n",
    "            compute_metrics = compute_metrics\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # trainer.train(resume_from_checkpoint=True)\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results.to_csv('sanad_results.csv')\n",
    "display(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b7f13-c4fa-4355-9192-11d71fbab952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382f88d-15fb-48d8-8b29-f328f6817a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
