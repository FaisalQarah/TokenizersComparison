{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 10:16:28.981887: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-19 10:16:29.007853: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-19 10:16:29.382112: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Found cached dataset csv (/home/ffq/.cache/huggingface/datasets/NoraAlt___csv/NoraAlt--Mawqif_Stance-Detection-5af5d638123fb939/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d813e77427e44acbb9fbbb4ac769ee16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Women empowerment', 'Covid Vaccine', 'Digital Transformation'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['تمكين المرأة', 'لقاح كوفيد', 'التحول الرقمي'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Against', 'neutral', 'Favor'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Against', 'neutral', 'Favor']\n",
       "Categories (3, object): ['Against', 'Favor', 'neutral']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'target', 'label'],\n",
       "        num_rows: 2801\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'target', 'label'],\n",
       "        num_rows: 701\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/701 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 00:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.743914</td>\n",
       "      <td>0.659058</td>\n",
       "      <td>0.422755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.679500</td>\n",
       "      <td>0.651334</td>\n",
       "      <td>0.714693</td>\n",
       "      <td>0.491613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.615600</td>\n",
       "      <td>0.620822</td>\n",
       "      <td>0.736091</td>\n",
       "      <td>0.549778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.554000</td>\n",
       "      <td>0.609371</td>\n",
       "      <td>0.723252</td>\n",
       "      <td>0.530997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.484700</td>\n",
       "      <td>0.636791</td>\n",
       "      <td>0.741797</td>\n",
       "      <td>0.563882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.478400</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>0.768902</td>\n",
       "      <td>0.665083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>0.600581</td>\n",
       "      <td>0.767475</td>\n",
       "      <td>0.607507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.334800</td>\n",
       "      <td>0.654747</td>\n",
       "      <td>0.757489</td>\n",
       "      <td>0.655027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.306900</td>\n",
       "      <td>0.695563</td>\n",
       "      <td>0.770328</td>\n",
       "      <td>0.628825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.714379</td>\n",
       "      <td>0.773181</td>\n",
       "      <td>0.669366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.747594</td>\n",
       "      <td>0.756063</td>\n",
       "      <td>0.652986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.771985</td>\n",
       "      <td>0.760342</td>\n",
       "      <td>0.633744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.812690</td>\n",
       "      <td>0.740371</td>\n",
       "      <td>0.644972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>0.876996</td>\n",
       "      <td>0.768902</td>\n",
       "      <td>0.665889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.933403</td>\n",
       "      <td>0.761769</td>\n",
       "      <td>0.642487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.968054</td>\n",
       "      <td>0.761769</td>\n",
       "      <td>0.657179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.994905</td>\n",
       "      <td>0.758916</td>\n",
       "      <td>0.651355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>1.031266</td>\n",
       "      <td>0.766049</td>\n",
       "      <td>0.655131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>1.068348</td>\n",
       "      <td>0.743224</td>\n",
       "      <td>0.636844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>1.073336</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.647028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1.089425</td>\n",
       "      <td>0.756063</td>\n",
       "      <td>0.656002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>1.082641</td>\n",
       "      <td>0.764622</td>\n",
       "      <td>0.663962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/701 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 00:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.892600</td>\n",
       "      <td>0.724681</td>\n",
       "      <td>0.684736</td>\n",
       "      <td>0.461276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.677500</td>\n",
       "      <td>0.674284</td>\n",
       "      <td>0.706134</td>\n",
       "      <td>0.480913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.644421</td>\n",
       "      <td>0.731812</td>\n",
       "      <td>0.515308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.562600</td>\n",
       "      <td>0.611533</td>\n",
       "      <td>0.730385</td>\n",
       "      <td>0.509629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.487300</td>\n",
       "      <td>0.651133</td>\n",
       "      <td>0.731812</td>\n",
       "      <td>0.523042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>0.620795</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.585354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>0.621668</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.602541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.362200</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.760342</td>\n",
       "      <td>0.651937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.318300</td>\n",
       "      <td>0.671607</td>\n",
       "      <td>0.764622</td>\n",
       "      <td>0.647809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.737218</td>\n",
       "      <td>0.761769</td>\n",
       "      <td>0.650557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.247900</td>\n",
       "      <td>0.772250</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.626965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.739608</td>\n",
       "      <td>0.767475</td>\n",
       "      <td>0.644877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.809515</td>\n",
       "      <td>0.747504</td>\n",
       "      <td>0.636486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.853262</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.660285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.986318</td>\n",
       "      <td>0.744650</td>\n",
       "      <td>0.623644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.937595</td>\n",
       "      <td>0.756063</td>\n",
       "      <td>0.639887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.966812</td>\n",
       "      <td>0.743224</td>\n",
       "      <td>0.644919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.974501</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.643502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.973748</td>\n",
       "      <td>0.753210</td>\n",
       "      <td>0.652782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>1.018170</td>\n",
       "      <td>0.748930</td>\n",
       "      <td>0.650163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>1.019973</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.644656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>1.015268</td>\n",
       "      <td>0.756063</td>\n",
       "      <td>0.655492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/701 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 00:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.892600</td>\n",
       "      <td>0.724681</td>\n",
       "      <td>0.684736</td>\n",
       "      <td>0.461276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.677500</td>\n",
       "      <td>0.674284</td>\n",
       "      <td>0.706134</td>\n",
       "      <td>0.480913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.644421</td>\n",
       "      <td>0.731812</td>\n",
       "      <td>0.515308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.562600</td>\n",
       "      <td>0.611533</td>\n",
       "      <td>0.730385</td>\n",
       "      <td>0.509629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.487300</td>\n",
       "      <td>0.651133</td>\n",
       "      <td>0.731812</td>\n",
       "      <td>0.523042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>0.620795</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.585354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>0.621668</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.602541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.362200</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.760342</td>\n",
       "      <td>0.651937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.318300</td>\n",
       "      <td>0.671607</td>\n",
       "      <td>0.764622</td>\n",
       "      <td>0.647809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.737218</td>\n",
       "      <td>0.761769</td>\n",
       "      <td>0.650557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.247900</td>\n",
       "      <td>0.772250</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.626965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.739608</td>\n",
       "      <td>0.767475</td>\n",
       "      <td>0.644877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.809515</td>\n",
       "      <td>0.747504</td>\n",
       "      <td>0.636486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.853262</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.660285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.986318</td>\n",
       "      <td>0.744650</td>\n",
       "      <td>0.623644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.937595</td>\n",
       "      <td>0.756063</td>\n",
       "      <td>0.639887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.966812</td>\n",
       "      <td>0.743224</td>\n",
       "      <td>0.644919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.974501</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.643502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.973748</td>\n",
       "      <td>0.753210</td>\n",
       "      <td>0.652782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>1.018170</td>\n",
       "      <td>0.748930</td>\n",
       "      <td>0.650163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>1.019973</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.644656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>1.015268</td>\n",
       "      <td>0.756063</td>\n",
       "      <td>0.655492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/701 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 00:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.888700</td>\n",
       "      <td>0.741033</td>\n",
       "      <td>0.693295</td>\n",
       "      <td>0.474202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.657962</td>\n",
       "      <td>0.714693</td>\n",
       "      <td>0.491580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.636109</td>\n",
       "      <td>0.728959</td>\n",
       "      <td>0.506695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.561700</td>\n",
       "      <td>0.633668</td>\n",
       "      <td>0.731812</td>\n",
       "      <td>0.513562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.483600</td>\n",
       "      <td>0.603316</td>\n",
       "      <td>0.738944</td>\n",
       "      <td>0.533304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.458300</td>\n",
       "      <td>0.606501</td>\n",
       "      <td>0.751783</td>\n",
       "      <td>0.619673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>0.665998</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.585342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>0.646195</td>\n",
       "      <td>0.773181</td>\n",
       "      <td>0.684598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.299200</td>\n",
       "      <td>0.669360</td>\n",
       "      <td>0.774608</td>\n",
       "      <td>0.661124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.742802</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.641112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.709932</td>\n",
       "      <td>0.771755</td>\n",
       "      <td>0.679690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.784316</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.627602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.148600</td>\n",
       "      <td>0.789112</td>\n",
       "      <td>0.756063</td>\n",
       "      <td>0.666467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.813403</td>\n",
       "      <td>0.776034</td>\n",
       "      <td>0.683824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>0.921629</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.632759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.860517</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.658272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>0.879973</td>\n",
       "      <td>0.751783</td>\n",
       "      <td>0.658221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.949392</td>\n",
       "      <td>0.747504</td>\n",
       "      <td>0.632185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.934251</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.648999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.942255</td>\n",
       "      <td>0.753210</td>\n",
       "      <td>0.654678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.654492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.956886</td>\n",
       "      <td>0.756063</td>\n",
       "      <td>0.657508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/701 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 00:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.888700</td>\n",
       "      <td>0.741033</td>\n",
       "      <td>0.693295</td>\n",
       "      <td>0.474202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.657962</td>\n",
       "      <td>0.714693</td>\n",
       "      <td>0.491580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.636109</td>\n",
       "      <td>0.728959</td>\n",
       "      <td>0.506695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.561700</td>\n",
       "      <td>0.633668</td>\n",
       "      <td>0.731812</td>\n",
       "      <td>0.513562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.483600</td>\n",
       "      <td>0.603316</td>\n",
       "      <td>0.738944</td>\n",
       "      <td>0.533304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.458300</td>\n",
       "      <td>0.606501</td>\n",
       "      <td>0.751783</td>\n",
       "      <td>0.619673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>0.665998</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.585342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>0.646195</td>\n",
       "      <td>0.773181</td>\n",
       "      <td>0.684598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.299200</td>\n",
       "      <td>0.669360</td>\n",
       "      <td>0.774608</td>\n",
       "      <td>0.661124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.742802</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.641112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.709932</td>\n",
       "      <td>0.771755</td>\n",
       "      <td>0.679690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.784316</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.627602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.148600</td>\n",
       "      <td>0.789112</td>\n",
       "      <td>0.756063</td>\n",
       "      <td>0.666467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.813403</td>\n",
       "      <td>0.776034</td>\n",
       "      <td>0.683824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>0.921629</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.632759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.860517</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.658272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>0.879973</td>\n",
       "      <td>0.751783</td>\n",
       "      <td>0.658221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.949392</td>\n",
       "      <td>0.747504</td>\n",
       "      <td>0.632185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.934251</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.648999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.942255</td>\n",
       "      <td>0.753210</td>\n",
       "      <td>0.654678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.654492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.956886</td>\n",
       "      <td>0.756063</td>\n",
       "      <td>0.657508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/701 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 00:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.888700</td>\n",
       "      <td>0.741033</td>\n",
       "      <td>0.693295</td>\n",
       "      <td>0.474202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.657962</td>\n",
       "      <td>0.714693</td>\n",
       "      <td>0.491580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.636109</td>\n",
       "      <td>0.728959</td>\n",
       "      <td>0.506695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.561700</td>\n",
       "      <td>0.633668</td>\n",
       "      <td>0.731812</td>\n",
       "      <td>0.513562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.483600</td>\n",
       "      <td>0.603316</td>\n",
       "      <td>0.738944</td>\n",
       "      <td>0.533304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.458300</td>\n",
       "      <td>0.606501</td>\n",
       "      <td>0.751783</td>\n",
       "      <td>0.619673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>0.665998</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.585342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>0.646195</td>\n",
       "      <td>0.773181</td>\n",
       "      <td>0.684598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.299200</td>\n",
       "      <td>0.669360</td>\n",
       "      <td>0.774608</td>\n",
       "      <td>0.661124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.742802</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.641112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.709932</td>\n",
       "      <td>0.771755</td>\n",
       "      <td>0.679690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.784316</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.627602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.148600</td>\n",
       "      <td>0.789112</td>\n",
       "      <td>0.756063</td>\n",
       "      <td>0.666467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.813403</td>\n",
       "      <td>0.776034</td>\n",
       "      <td>0.683824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>0.921629</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.632759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.860517</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.658272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>0.879973</td>\n",
       "      <td>0.751783</td>\n",
       "      <td>0.658221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.949392</td>\n",
       "      <td>0.747504</td>\n",
       "      <td>0.632185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.934251</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.648999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.942255</td>\n",
       "      <td>0.753210</td>\n",
       "      <td>0.654678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.654492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.956886</td>\n",
       "      <td>0.756063</td>\n",
       "      <td>0.657508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/701 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 00:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.905400</td>\n",
       "      <td>0.753982</td>\n",
       "      <td>0.674750</td>\n",
       "      <td>0.456541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.683275</td>\n",
       "      <td>0.708987</td>\n",
       "      <td>0.488947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.654829</td>\n",
       "      <td>0.714693</td>\n",
       "      <td>0.515886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.572400</td>\n",
       "      <td>0.633591</td>\n",
       "      <td>0.720399</td>\n",
       "      <td>0.525210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.621555</td>\n",
       "      <td>0.727532</td>\n",
       "      <td>0.584462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>0.662604</td>\n",
       "      <td>0.724679</td>\n",
       "      <td>0.611437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.672060</td>\n",
       "      <td>0.727532</td>\n",
       "      <td>0.607115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.661260</td>\n",
       "      <td>0.748930</td>\n",
       "      <td>0.645981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.333100</td>\n",
       "      <td>0.722104</td>\n",
       "      <td>0.734665</td>\n",
       "      <td>0.621028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.262800</td>\n",
       "      <td>0.720915</td>\n",
       "      <td>0.748930</td>\n",
       "      <td>0.643588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.265400</td>\n",
       "      <td>0.728594</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.644227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.755450</td>\n",
       "      <td>0.747504</td>\n",
       "      <td>0.622196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.832590</td>\n",
       "      <td>0.738944</td>\n",
       "      <td>0.624534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.847873</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.658869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.154500</td>\n",
       "      <td>0.919054</td>\n",
       "      <td>0.737518</td>\n",
       "      <td>0.624359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.899871</td>\n",
       "      <td>0.738944</td>\n",
       "      <td>0.645612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.930368</td>\n",
       "      <td>0.741797</td>\n",
       "      <td>0.648746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.992233</td>\n",
       "      <td>0.743224</td>\n",
       "      <td>0.619285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.949670</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.641159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>0.962469</td>\n",
       "      <td>0.740371</td>\n",
       "      <td>0.646032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.975561</td>\n",
       "      <td>0.744650</td>\n",
       "      <td>0.646181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.984950</td>\n",
       "      <td>0.743224</td>\n",
       "      <td>0.645205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/701 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 00:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.905400</td>\n",
       "      <td>0.753982</td>\n",
       "      <td>0.674750</td>\n",
       "      <td>0.456541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.683275</td>\n",
       "      <td>0.708987</td>\n",
       "      <td>0.488947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.654829</td>\n",
       "      <td>0.714693</td>\n",
       "      <td>0.515886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.572400</td>\n",
       "      <td>0.633591</td>\n",
       "      <td>0.720399</td>\n",
       "      <td>0.525210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.621555</td>\n",
       "      <td>0.727532</td>\n",
       "      <td>0.584462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>0.662604</td>\n",
       "      <td>0.724679</td>\n",
       "      <td>0.611437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.672060</td>\n",
       "      <td>0.727532</td>\n",
       "      <td>0.607115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.661260</td>\n",
       "      <td>0.748930</td>\n",
       "      <td>0.645981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.333100</td>\n",
       "      <td>0.722104</td>\n",
       "      <td>0.734665</td>\n",
       "      <td>0.621028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.262800</td>\n",
       "      <td>0.720915</td>\n",
       "      <td>0.748930</td>\n",
       "      <td>0.643588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.265400</td>\n",
       "      <td>0.728594</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.644227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.755450</td>\n",
       "      <td>0.747504</td>\n",
       "      <td>0.622196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.832590</td>\n",
       "      <td>0.738944</td>\n",
       "      <td>0.624534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.847873</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.658869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.154500</td>\n",
       "      <td>0.919054</td>\n",
       "      <td>0.737518</td>\n",
       "      <td>0.624359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.899871</td>\n",
       "      <td>0.738944</td>\n",
       "      <td>0.645612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.930368</td>\n",
       "      <td>0.741797</td>\n",
       "      <td>0.648746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.992233</td>\n",
       "      <td>0.743224</td>\n",
       "      <td>0.619285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.949670</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.641159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>0.962469</td>\n",
       "      <td>0.740371</td>\n",
       "      <td>0.646032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.975561</td>\n",
       "      <td>0.744650</td>\n",
       "      <td>0.646181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.984950</td>\n",
       "      <td>0.743224</td>\n",
       "      <td>0.645205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/701 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 00:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.905400</td>\n",
       "      <td>0.753982</td>\n",
       "      <td>0.674750</td>\n",
       "      <td>0.456541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.683275</td>\n",
       "      <td>0.708987</td>\n",
       "      <td>0.488947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.654829</td>\n",
       "      <td>0.714693</td>\n",
       "      <td>0.515886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.572400</td>\n",
       "      <td>0.633591</td>\n",
       "      <td>0.720399</td>\n",
       "      <td>0.525210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.621555</td>\n",
       "      <td>0.727532</td>\n",
       "      <td>0.584462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>0.662604</td>\n",
       "      <td>0.724679</td>\n",
       "      <td>0.611437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.672060</td>\n",
       "      <td>0.727532</td>\n",
       "      <td>0.607115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.661260</td>\n",
       "      <td>0.748930</td>\n",
       "      <td>0.645981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.333100</td>\n",
       "      <td>0.722104</td>\n",
       "      <td>0.734665</td>\n",
       "      <td>0.621028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.262800</td>\n",
       "      <td>0.720915</td>\n",
       "      <td>0.748930</td>\n",
       "      <td>0.643588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.265400</td>\n",
       "      <td>0.728594</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.644227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.755450</td>\n",
       "      <td>0.747504</td>\n",
       "      <td>0.622196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.832590</td>\n",
       "      <td>0.738944</td>\n",
       "      <td>0.624534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.847873</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.658869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.154500</td>\n",
       "      <td>0.919054</td>\n",
       "      <td>0.737518</td>\n",
       "      <td>0.624359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.899871</td>\n",
       "      <td>0.738944</td>\n",
       "      <td>0.645612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.930368</td>\n",
       "      <td>0.741797</td>\n",
       "      <td>0.648746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.992233</td>\n",
       "      <td>0.743224</td>\n",
       "      <td>0.619285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.949670</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.641159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>0.962469</td>\n",
       "      <td>0.740371</td>\n",
       "      <td>0.646032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.975561</td>\n",
       "      <td>0.744650</td>\n",
       "      <td>0.646181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.984950</td>\n",
       "      <td>0.743224</td>\n",
       "      <td>0.645205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faisalq/bert-base-arabic-bbpe</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.658869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>faisalq/bert-base-arabic-senpiece</td>\n",
       "      <td>0.773181</td>\n",
       "      <td>0.684598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/bert-base-arabic-wordpiece</td>\n",
       "      <td>0.773181</td>\n",
       "      <td>0.669366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  Accuracy        F1\n",
       "0       faisalq/bert-base-arabic-bbpe  0.750357  0.658869\n",
       "3   faisalq/bert-base-arabic-senpiece  0.773181  0.684598\n",
       "6  faisalq/bert-base-arabic-wordpiece  0.773181  0.669366"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "log_file = 'Mawqif_stance.txt'\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "\n",
    "ds = load_dataset('NoraAlt/Mawqif_Stance-Detection')\n",
    "ds = ds['train']\n",
    "df = ds.to_pandas()\n",
    "\n",
    "\n",
    "# ['target', 'stance', 'sarcasm']\n",
    "df = df[['text', 'target', 'stance']]\n",
    "\n",
    "display(df['target'].unique())\n",
    "\n",
    "df.fillna('neutral', inplace=True)\n",
    "\n",
    "\n",
    "df['target'] = df['target'].replace('Women empowerment', 'تمكين المرأة')\n",
    "df['target'] = df['target'].replace('Covid Vaccine', 'لقاح كوفيد')\n",
    "df['target'] = df['target'].replace('Digital Transformation', 'التحول الرقمي')\n",
    "display(df['target'].unique())\n",
    "display(df['stance'].unique())\n",
    "df['stance'] = df['stance'].astype('category')\n",
    "\n",
    "df['label'] = df['stance'].cat.codes\n",
    "classes = df['stance'].unique()\n",
    "classes_num = len(classes)\n",
    "display(classes)\n",
    "display(classes_num)\n",
    "\n",
    "df = df[['text', 'target', 'label']]\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "# ds = ds['train']\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "display(ds)\n",
    "# df = ''\n",
    "\n",
    "\n",
    "# return\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "# classes_num = 5\n",
    "# display(classes_num)\n",
    "# display(ds)\n",
    "\n",
    "\n",
    "models = ['faisalq/bert-base-arabic-wordpiece', 'faisalq/bert-base-arabic-senpiece',\n",
    "          'faisalq/bert-base-arabic-bbpe']\n",
    "\n",
    "\n",
    "for model_name in models:\n",
    "    for i in range(3):\n",
    "        print(f'{model_name}, try:{i}')\n",
    "              \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = BertForSequenceClassification.from_pretrained(model_name,\n",
    "                                                              num_labels=classes_num).to('cuda')                                                 \n",
    "        dataset_train = ds['train']\n",
    "        dataset_validation = ds['test']                                                     \n",
    "        \n",
    "      \n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            return tokenizer(examples['text'], examples['target'], truncation=True, padding=\"max_length\",\n",
    "                            max_length=max_sequence_length)\n",
    "        \n",
    "        \n",
    "        dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "        dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "        \n",
    "       \n",
    "        \n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)    \n",
    "            acc = accuracy_score(labels, predictions)        \n",
    "            f1 = f1_score(labels, predictions, average='macro')   \n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{model_name},{acc},{f1}\\n')\n",
    "            return {'accuracy': acc, 'f1_score': f1}\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        epochs = 10\n",
    "        save_steps = 10000 #save checkpoint every 10000 steps\n",
    "        batch_size = 256\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = 'bert/',\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs = epochs,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            save_steps = save_steps,\n",
    "            save_total_limit = 1, #only save the last 5 checkpoints\n",
    "            fp16=True,\n",
    "            learning_rate = 5e-5,  # 5e-5 is the default\n",
    "            logging_steps = 5, #50_000\n",
    "            evaluation_strategy = 'steps',\n",
    "            # evaluate_during_training = True,\n",
    "            eval_steps = 5\n",
    "            \n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args = training_args,\n",
    "            # data_collator=data_collator,\n",
    "            train_dataset=dataset_train,\n",
    "            eval_dataset=dataset_validation,\n",
    "            compute_metrics = compute_metrics\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # trainer.train(resume_from_checkpoint=True)\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv('Mawqif_stance_results.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b7f13-c4fa-4355-9192-11d71fbab952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382f88d-15fb-48d8-8b29-f328f6817a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb4923-7e46-4c22-a4b7-0321fdc9c707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
