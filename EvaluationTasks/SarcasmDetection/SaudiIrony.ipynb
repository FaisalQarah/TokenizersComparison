{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 07:28:30.405331: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-21 07:28:30.430331: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-21 07:28:30.798220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Tweet ID', 'Tweets with Decoded emojis', 'Final Annotation'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Tweets with Decoded emojis</th>\n",
       "      <th>Final Annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>نعم من علامات الجمال تلك الطيبه التي لاترى بل العين ولكنها تلمس القلب هذا هو الجمال الذي لايشيخ ابدا مساء الخيرات على كل من يحب السلام والخير ربي يحفظكم</td>\n",
       "      <td>ليست تهكم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>المعرفه الجديده والمهارات الجديده واعتماد طرائق جديده في النظر الى الكون هي التي تبقي العقل والجسد في حال من النمو ويتجلى ذلك في التصميم على البقاء في حال من الجده في كل ثانيه من ثواني العمر دديباك شوبرا جسد لايشيخ عقل يتخطى الزمن</td>\n",
       "      <td>ليست تهكم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>لايشيخ</td>\n",
       "      <td>تهكم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>لايشيخ وكورونا بتزيده مناعه يعني كورونا العن ترا انا مناعتي ضعيفه وجتني اعراض من اللقاح يوم وراحت لو انها كورونا كان جت الاعراض اقوى وتستمر ايام</td>\n",
       "      <td>تهكم</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet ID   \n",
       "0         1  \\\n",
       "1         2   \n",
       "2         3   \n",
       "3         4   \n",
       "\n",
       "                                                                                                                                                                                                               Tweets with Decoded emojis   \n",
       "0                                                                                نعم من علامات الجمال تلك الطيبه التي لاترى بل العين ولكنها تلمس القلب هذا هو الجمال الذي لايشيخ ابدا مساء الخيرات على كل من يحب السلام والخير ربي يحفظكم  \\\n",
       "1  المعرفه الجديده والمهارات الجديده واعتماد طرائق جديده في النظر الى الكون هي التي تبقي العقل والجسد في حال من النمو ويتجلى ذلك في التصميم على البقاء في حال من الجده في كل ثانيه من ثواني العمر دديباك شوبرا جسد لايشيخ عقل يتخطى الزمن   \n",
       "2                                                                                                                                                                                                                                  لايشيخ   \n",
       "3                                                                                        لايشيخ وكورونا بتزيده مناعه يعني كورونا العن ترا انا مناعتي ضعيفه وجتني اعراض من اللقاح يوم وراحت لو انها كورونا كان جت الاعراض اقوى وتستمر ايام   \n",
       "\n",
       "  Final Annotation  \n",
       "0        ليست تهكم  \n",
       "1        ليست تهكم  \n",
       "2             تهكم  \n",
       "3             تهكم  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'تهكم', 'ليست تهكم'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "19635"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 15708\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 3927\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3927 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 03:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>0.585285</td>\n",
       "      <td>0.695442</td>\n",
       "      <td>0.672801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.596600</td>\n",
       "      <td>0.584106</td>\n",
       "      <td>0.700025</td>\n",
       "      <td>0.672893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.583200</td>\n",
       "      <td>0.567993</td>\n",
       "      <td>0.714540</td>\n",
       "      <td>0.699664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.545200</td>\n",
       "      <td>0.577857</td>\n",
       "      <td>0.710975</td>\n",
       "      <td>0.699231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.585158</td>\n",
       "      <td>0.716068</td>\n",
       "      <td>0.702112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.548300</td>\n",
       "      <td>0.567233</td>\n",
       "      <td>0.715814</td>\n",
       "      <td>0.701741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.479500</td>\n",
       "      <td>0.649834</td>\n",
       "      <td>0.682964</td>\n",
       "      <td>0.676190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.464900</td>\n",
       "      <td>0.624663</td>\n",
       "      <td>0.699007</td>\n",
       "      <td>0.687263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>0.645529</td>\n",
       "      <td>0.683219</td>\n",
       "      <td>0.680335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.389600</td>\n",
       "      <td>0.744244</td>\n",
       "      <td>0.684747</td>\n",
       "      <td>0.672845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.756699</td>\n",
       "      <td>0.681182</td>\n",
       "      <td>0.656885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.345500</td>\n",
       "      <td>0.786348</td>\n",
       "      <td>0.672014</td>\n",
       "      <td>0.663877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.300900</td>\n",
       "      <td>0.863190</td>\n",
       "      <td>0.664629</td>\n",
       "      <td>0.655942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.951600</td>\n",
       "      <td>0.673797</td>\n",
       "      <td>0.659746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.268500</td>\n",
       "      <td>0.919359</td>\n",
       "      <td>0.674306</td>\n",
       "      <td>0.649229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>1.006655</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.637826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.181100</td>\n",
       "      <td>1.113771</td>\n",
       "      <td>0.654953</td>\n",
       "      <td>0.632729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>1.079045</td>\n",
       "      <td>0.670741</td>\n",
       "      <td>0.646518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>1.198846</td>\n",
       "      <td>0.658009</td>\n",
       "      <td>0.643124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>1.322505</td>\n",
       "      <td>0.655208</td>\n",
       "      <td>0.641828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>1.244113</td>\n",
       "      <td>0.664375</td>\n",
       "      <td>0.645374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>1.249278</td>\n",
       "      <td>0.658263</td>\n",
       "      <td>0.640065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>1.436459</td>\n",
       "      <td>0.650624</td>\n",
       "      <td>0.621864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>1.403062</td>\n",
       "      <td>0.661064</td>\n",
       "      <td>0.641742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>1.416942</td>\n",
       "      <td>0.653680</td>\n",
       "      <td>0.635061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>1.477430</td>\n",
       "      <td>0.659282</td>\n",
       "      <td>0.640526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>1.521190</td>\n",
       "      <td>0.657754</td>\n",
       "      <td>0.629694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>1.515831</td>\n",
       "      <td>0.654698</td>\n",
       "      <td>0.631314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>1.557266</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>0.635269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>1.577711</td>\n",
       "      <td>0.657754</td>\n",
       "      <td>0.638198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>1.573981</td>\n",
       "      <td>0.657499</td>\n",
       "      <td>0.637883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3927 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 03:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.624600</td>\n",
       "      <td>0.585028</td>\n",
       "      <td>0.703591</td>\n",
       "      <td>0.681280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.597200</td>\n",
       "      <td>0.578630</td>\n",
       "      <td>0.702317</td>\n",
       "      <td>0.675444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.590400</td>\n",
       "      <td>0.577864</td>\n",
       "      <td>0.710466</td>\n",
       "      <td>0.683410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.578247</td>\n",
       "      <td>0.716323</td>\n",
       "      <td>0.704578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.549700</td>\n",
       "      <td>0.581299</td>\n",
       "      <td>0.712503</td>\n",
       "      <td>0.699530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.567750</td>\n",
       "      <td>0.708683</td>\n",
       "      <td>0.699976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.483300</td>\n",
       "      <td>0.623085</td>\n",
       "      <td>0.692641</td>\n",
       "      <td>0.681764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.465800</td>\n",
       "      <td>0.637548</td>\n",
       "      <td>0.688821</td>\n",
       "      <td>0.663308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>0.652218</td>\n",
       "      <td>0.690858</td>\n",
       "      <td>0.684181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.395600</td>\n",
       "      <td>0.740020</td>\n",
       "      <td>0.689840</td>\n",
       "      <td>0.673480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.769066</td>\n",
       "      <td>0.692641</td>\n",
       "      <td>0.673790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.346900</td>\n",
       "      <td>0.772991</td>\n",
       "      <td>0.677617</td>\n",
       "      <td>0.671750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.801860</td>\n",
       "      <td>0.680927</td>\n",
       "      <td>0.670944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.961077</td>\n",
       "      <td>0.680927</td>\n",
       "      <td>0.660012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.934131</td>\n",
       "      <td>0.669213</td>\n",
       "      <td>0.656129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.204600</td>\n",
       "      <td>0.997547</td>\n",
       "      <td>0.659282</td>\n",
       "      <td>0.645325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>1.146410</td>\n",
       "      <td>0.652916</td>\n",
       "      <td>0.632480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>1.125259</td>\n",
       "      <td>0.667176</td>\n",
       "      <td>0.642382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>1.170912</td>\n",
       "      <td>0.664120</td>\n",
       "      <td>0.653738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>1.343310</td>\n",
       "      <td>0.661828</td>\n",
       "      <td>0.652090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>1.242584</td>\n",
       "      <td>0.666157</td>\n",
       "      <td>0.653449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>1.262312</td>\n",
       "      <td>0.658009</td>\n",
       "      <td>0.639404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>1.390328</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.636316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>1.400037</td>\n",
       "      <td>0.654698</td>\n",
       "      <td>0.637346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>1.409725</td>\n",
       "      <td>0.659282</td>\n",
       "      <td>0.645176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>1.456487</td>\n",
       "      <td>0.653680</td>\n",
       "      <td>0.645145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>1.481922</td>\n",
       "      <td>0.662592</td>\n",
       "      <td>0.645177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>1.468437</td>\n",
       "      <td>0.660555</td>\n",
       "      <td>0.648198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>1.519082</td>\n",
       "      <td>0.658518</td>\n",
       "      <td>0.646843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>1.535520</td>\n",
       "      <td>0.662083</td>\n",
       "      <td>0.647375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>1.535869</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.647832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-wordpiece, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-wordpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3927 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 03:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.624600</td>\n",
       "      <td>0.585028</td>\n",
       "      <td>0.703591</td>\n",
       "      <td>0.681280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.597200</td>\n",
       "      <td>0.578630</td>\n",
       "      <td>0.702317</td>\n",
       "      <td>0.675444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.590400</td>\n",
       "      <td>0.577864</td>\n",
       "      <td>0.710466</td>\n",
       "      <td>0.683410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.578247</td>\n",
       "      <td>0.716323</td>\n",
       "      <td>0.704578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.549700</td>\n",
       "      <td>0.581299</td>\n",
       "      <td>0.712503</td>\n",
       "      <td>0.699530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.567750</td>\n",
       "      <td>0.708683</td>\n",
       "      <td>0.699976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.483300</td>\n",
       "      <td>0.623085</td>\n",
       "      <td>0.692641</td>\n",
       "      <td>0.681764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.465800</td>\n",
       "      <td>0.637548</td>\n",
       "      <td>0.688821</td>\n",
       "      <td>0.663308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>0.652218</td>\n",
       "      <td>0.690858</td>\n",
       "      <td>0.684181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.395600</td>\n",
       "      <td>0.740020</td>\n",
       "      <td>0.689840</td>\n",
       "      <td>0.673480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.769066</td>\n",
       "      <td>0.692641</td>\n",
       "      <td>0.673790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.346900</td>\n",
       "      <td>0.772991</td>\n",
       "      <td>0.677617</td>\n",
       "      <td>0.671750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.801860</td>\n",
       "      <td>0.680927</td>\n",
       "      <td>0.670944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.961077</td>\n",
       "      <td>0.680927</td>\n",
       "      <td>0.660012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.934131</td>\n",
       "      <td>0.669213</td>\n",
       "      <td>0.656129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.204600</td>\n",
       "      <td>0.997547</td>\n",
       "      <td>0.659282</td>\n",
       "      <td>0.645325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>1.146410</td>\n",
       "      <td>0.652916</td>\n",
       "      <td>0.632480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>1.125259</td>\n",
       "      <td>0.667176</td>\n",
       "      <td>0.642382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>1.170912</td>\n",
       "      <td>0.664120</td>\n",
       "      <td>0.653738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>1.343310</td>\n",
       "      <td>0.661828</td>\n",
       "      <td>0.652090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>1.242584</td>\n",
       "      <td>0.666157</td>\n",
       "      <td>0.653449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>1.262312</td>\n",
       "      <td>0.658009</td>\n",
       "      <td>0.639404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>1.390328</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.636316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>1.400037</td>\n",
       "      <td>0.654698</td>\n",
       "      <td>0.637346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>1.409725</td>\n",
       "      <td>0.659282</td>\n",
       "      <td>0.645176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>1.456487</td>\n",
       "      <td>0.653680</td>\n",
       "      <td>0.645145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>1.481922</td>\n",
       "      <td>0.662592</td>\n",
       "      <td>0.645177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>1.468437</td>\n",
       "      <td>0.660555</td>\n",
       "      <td>0.648198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>1.519082</td>\n",
       "      <td>0.658518</td>\n",
       "      <td>0.646843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>1.535520</td>\n",
       "      <td>0.662083</td>\n",
       "      <td>0.647375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>1.535869</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.647832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3927 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 03:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.625400</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.703336</td>\n",
       "      <td>0.683461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.590100</td>\n",
       "      <td>0.580594</td>\n",
       "      <td>0.708683</td>\n",
       "      <td>0.685556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.582400</td>\n",
       "      <td>0.581798</td>\n",
       "      <td>0.702317</td>\n",
       "      <td>0.675959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.551400</td>\n",
       "      <td>0.573806</td>\n",
       "      <td>0.717087</td>\n",
       "      <td>0.704580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.542200</td>\n",
       "      <td>0.581871</td>\n",
       "      <td>0.713267</td>\n",
       "      <td>0.702382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>0.570844</td>\n",
       "      <td>0.711485</td>\n",
       "      <td>0.702512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.480800</td>\n",
       "      <td>0.636816</td>\n",
       "      <td>0.678380</td>\n",
       "      <td>0.666999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.452200</td>\n",
       "      <td>0.624143</td>\n",
       "      <td>0.681691</td>\n",
       "      <td>0.673089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.455800</td>\n",
       "      <td>0.638139</td>\n",
       "      <td>0.683983</td>\n",
       "      <td>0.676836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.371400</td>\n",
       "      <td>0.744485</td>\n",
       "      <td>0.671250</td>\n",
       "      <td>0.662048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.332800</td>\n",
       "      <td>0.808871</td>\n",
       "      <td>0.673542</td>\n",
       "      <td>0.667874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.805188</td>\n",
       "      <td>0.682964</td>\n",
       "      <td>0.671029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.888429</td>\n",
       "      <td>0.662847</td>\n",
       "      <td>0.650189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>1.015456</td>\n",
       "      <td>0.653425</td>\n",
       "      <td>0.647044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.951315</td>\n",
       "      <td>0.665648</td>\n",
       "      <td>0.649295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>1.073376</td>\n",
       "      <td>0.650115</td>\n",
       "      <td>0.643447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>1.204827</td>\n",
       "      <td>0.651642</td>\n",
       "      <td>0.641358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>1.192951</td>\n",
       "      <td>0.669722</td>\n",
       "      <td>0.656302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>1.230804</td>\n",
       "      <td>0.655971</td>\n",
       "      <td>0.649735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>1.300594</td>\n",
       "      <td>0.653170</td>\n",
       "      <td>0.637399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>1.322481</td>\n",
       "      <td>0.662592</td>\n",
       "      <td>0.646655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>1.326391</td>\n",
       "      <td>0.658263</td>\n",
       "      <td>0.645927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>1.424004</td>\n",
       "      <td>0.647823</td>\n",
       "      <td>0.638760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>1.459851</td>\n",
       "      <td>0.653680</td>\n",
       "      <td>0.637689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>1.503152</td>\n",
       "      <td>0.654444</td>\n",
       "      <td>0.638529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>1.503743</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.639652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>1.524791</td>\n",
       "      <td>0.654698</td>\n",
       "      <td>0.642304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>1.544339</td>\n",
       "      <td>0.649860</td>\n",
       "      <td>0.641941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>1.580641</td>\n",
       "      <td>0.654953</td>\n",
       "      <td>0.645599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>1.577149</td>\n",
       "      <td>0.653680</td>\n",
       "      <td>0.639645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.584854</td>\n",
       "      <td>0.650624</td>\n",
       "      <td>0.641060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3927 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 03:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.625400</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.703336</td>\n",
       "      <td>0.683461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.590100</td>\n",
       "      <td>0.580594</td>\n",
       "      <td>0.708683</td>\n",
       "      <td>0.685556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.582400</td>\n",
       "      <td>0.581798</td>\n",
       "      <td>0.702317</td>\n",
       "      <td>0.675959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.551400</td>\n",
       "      <td>0.573806</td>\n",
       "      <td>0.717087</td>\n",
       "      <td>0.704580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.542200</td>\n",
       "      <td>0.581871</td>\n",
       "      <td>0.713267</td>\n",
       "      <td>0.702382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>0.570844</td>\n",
       "      <td>0.711485</td>\n",
       "      <td>0.702512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.480800</td>\n",
       "      <td>0.636816</td>\n",
       "      <td>0.678380</td>\n",
       "      <td>0.666999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.452200</td>\n",
       "      <td>0.624143</td>\n",
       "      <td>0.681691</td>\n",
       "      <td>0.673089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.455800</td>\n",
       "      <td>0.638139</td>\n",
       "      <td>0.683983</td>\n",
       "      <td>0.676836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.371400</td>\n",
       "      <td>0.744485</td>\n",
       "      <td>0.671250</td>\n",
       "      <td>0.662048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.332800</td>\n",
       "      <td>0.808871</td>\n",
       "      <td>0.673542</td>\n",
       "      <td>0.667874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.805188</td>\n",
       "      <td>0.682964</td>\n",
       "      <td>0.671029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.888429</td>\n",
       "      <td>0.662847</td>\n",
       "      <td>0.650189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>1.015456</td>\n",
       "      <td>0.653425</td>\n",
       "      <td>0.647044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.951315</td>\n",
       "      <td>0.665648</td>\n",
       "      <td>0.649295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>1.073376</td>\n",
       "      <td>0.650115</td>\n",
       "      <td>0.643447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>1.204827</td>\n",
       "      <td>0.651642</td>\n",
       "      <td>0.641358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>1.192951</td>\n",
       "      <td>0.669722</td>\n",
       "      <td>0.656302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>1.230804</td>\n",
       "      <td>0.655971</td>\n",
       "      <td>0.649735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>1.300594</td>\n",
       "      <td>0.653170</td>\n",
       "      <td>0.637399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>1.322481</td>\n",
       "      <td>0.662592</td>\n",
       "      <td>0.646655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>1.326391</td>\n",
       "      <td>0.658263</td>\n",
       "      <td>0.645927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>1.424004</td>\n",
       "      <td>0.647823</td>\n",
       "      <td>0.638760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>1.459851</td>\n",
       "      <td>0.653680</td>\n",
       "      <td>0.637689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>1.503152</td>\n",
       "      <td>0.654444</td>\n",
       "      <td>0.638529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>1.503743</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.639652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>1.524791</td>\n",
       "      <td>0.654698</td>\n",
       "      <td>0.642304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>1.544339</td>\n",
       "      <td>0.649860</td>\n",
       "      <td>0.641941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>1.580641</td>\n",
       "      <td>0.654953</td>\n",
       "      <td>0.645599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>1.577149</td>\n",
       "      <td>0.653680</td>\n",
       "      <td>0.639645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.584854</td>\n",
       "      <td>0.650624</td>\n",
       "      <td>0.641060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-senpiece, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-senpiece and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3927 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 03:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.625400</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.703336</td>\n",
       "      <td>0.683461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.590100</td>\n",
       "      <td>0.580594</td>\n",
       "      <td>0.708683</td>\n",
       "      <td>0.685556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.582400</td>\n",
       "      <td>0.581798</td>\n",
       "      <td>0.702317</td>\n",
       "      <td>0.675959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.551400</td>\n",
       "      <td>0.573806</td>\n",
       "      <td>0.717087</td>\n",
       "      <td>0.704580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.542200</td>\n",
       "      <td>0.581871</td>\n",
       "      <td>0.713267</td>\n",
       "      <td>0.702382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>0.570844</td>\n",
       "      <td>0.711485</td>\n",
       "      <td>0.702512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.480800</td>\n",
       "      <td>0.636816</td>\n",
       "      <td>0.678380</td>\n",
       "      <td>0.666999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.452200</td>\n",
       "      <td>0.624143</td>\n",
       "      <td>0.681691</td>\n",
       "      <td>0.673089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.455800</td>\n",
       "      <td>0.638139</td>\n",
       "      <td>0.683983</td>\n",
       "      <td>0.676836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.371400</td>\n",
       "      <td>0.744485</td>\n",
       "      <td>0.671250</td>\n",
       "      <td>0.662048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.332800</td>\n",
       "      <td>0.808871</td>\n",
       "      <td>0.673542</td>\n",
       "      <td>0.667874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.805188</td>\n",
       "      <td>0.682964</td>\n",
       "      <td>0.671029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.888429</td>\n",
       "      <td>0.662847</td>\n",
       "      <td>0.650189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>1.015456</td>\n",
       "      <td>0.653425</td>\n",
       "      <td>0.647044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.951315</td>\n",
       "      <td>0.665648</td>\n",
       "      <td>0.649295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>1.073376</td>\n",
       "      <td>0.650115</td>\n",
       "      <td>0.643447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>1.204827</td>\n",
       "      <td>0.651642</td>\n",
       "      <td>0.641358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>1.192951</td>\n",
       "      <td>0.669722</td>\n",
       "      <td>0.656302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>1.230804</td>\n",
       "      <td>0.655971</td>\n",
       "      <td>0.649735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>1.300594</td>\n",
       "      <td>0.653170</td>\n",
       "      <td>0.637399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>1.322481</td>\n",
       "      <td>0.662592</td>\n",
       "      <td>0.646655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>1.326391</td>\n",
       "      <td>0.658263</td>\n",
       "      <td>0.645927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>1.424004</td>\n",
       "      <td>0.647823</td>\n",
       "      <td>0.638760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>1.459851</td>\n",
       "      <td>0.653680</td>\n",
       "      <td>0.637689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>1.503152</td>\n",
       "      <td>0.654444</td>\n",
       "      <td>0.638529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>1.503743</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.639652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>1.524791</td>\n",
       "      <td>0.654698</td>\n",
       "      <td>0.642304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>1.544339</td>\n",
       "      <td>0.649860</td>\n",
       "      <td>0.641941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>1.580641</td>\n",
       "      <td>0.654953</td>\n",
       "      <td>0.645599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>1.577149</td>\n",
       "      <td>0.653680</td>\n",
       "      <td>0.639645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.584854</td>\n",
       "      <td>0.650624</td>\n",
       "      <td>0.641060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3927 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 03:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.619600</td>\n",
       "      <td>0.591031</td>\n",
       "      <td>0.695187</td>\n",
       "      <td>0.682534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.589700</td>\n",
       "      <td>0.577393</td>\n",
       "      <td>0.703845</td>\n",
       "      <td>0.678430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.575674</td>\n",
       "      <td>0.711485</td>\n",
       "      <td>0.693550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.544700</td>\n",
       "      <td>0.578697</td>\n",
       "      <td>0.707156</td>\n",
       "      <td>0.695160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>0.582269</td>\n",
       "      <td>0.709447</td>\n",
       "      <td>0.698570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.577919</td>\n",
       "      <td>0.708429</td>\n",
       "      <td>0.699741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>0.651652</td>\n",
       "      <td>0.674051</td>\n",
       "      <td>0.654552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.431900</td>\n",
       "      <td>0.666793</td>\n",
       "      <td>0.684492</td>\n",
       "      <td>0.672811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.442800</td>\n",
       "      <td>0.666465</td>\n",
       "      <td>0.680672</td>\n",
       "      <td>0.675517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.777209</td>\n",
       "      <td>0.673033</td>\n",
       "      <td>0.661096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.809427</td>\n",
       "      <td>0.665139</td>\n",
       "      <td>0.653557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.798089</td>\n",
       "      <td>0.676853</td>\n",
       "      <td>0.663007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.907359</td>\n",
       "      <td>0.659537</td>\n",
       "      <td>0.648495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>1.006727</td>\n",
       "      <td>0.657499</td>\n",
       "      <td>0.642044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.992413</td>\n",
       "      <td>0.656481</td>\n",
       "      <td>0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>1.064947</td>\n",
       "      <td>0.653425</td>\n",
       "      <td>0.643601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>1.120500</td>\n",
       "      <td>0.647313</td>\n",
       "      <td>0.639225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>1.114988</td>\n",
       "      <td>0.652661</td>\n",
       "      <td>0.638050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>1.220093</td>\n",
       "      <td>0.648077</td>\n",
       "      <td>0.638444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>1.310778</td>\n",
       "      <td>0.648841</td>\n",
       "      <td>0.639565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>1.294463</td>\n",
       "      <td>0.654953</td>\n",
       "      <td>0.646074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>1.308861</td>\n",
       "      <td>0.669213</td>\n",
       "      <td>0.657574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>1.396459</td>\n",
       "      <td>0.664120</td>\n",
       "      <td>0.652770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>1.416045</td>\n",
       "      <td>0.651133</td>\n",
       "      <td>0.639241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>1.445819</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.637669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>1.453815</td>\n",
       "      <td>0.651133</td>\n",
       "      <td>0.637222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>1.498427</td>\n",
       "      <td>0.655971</td>\n",
       "      <td>0.640287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>1.513532</td>\n",
       "      <td>0.651642</td>\n",
       "      <td>0.638925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>1.555899</td>\n",
       "      <td>0.658263</td>\n",
       "      <td>0.650723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>1.557432</td>\n",
       "      <td>0.653934</td>\n",
       "      <td>0.642375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>1.557866</td>\n",
       "      <td>0.650115</td>\n",
       "      <td>0.639135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3927 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 03:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.619600</td>\n",
       "      <td>0.591031</td>\n",
       "      <td>0.695187</td>\n",
       "      <td>0.682534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.589700</td>\n",
       "      <td>0.577393</td>\n",
       "      <td>0.703845</td>\n",
       "      <td>0.678430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.575674</td>\n",
       "      <td>0.711485</td>\n",
       "      <td>0.693550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.544700</td>\n",
       "      <td>0.578697</td>\n",
       "      <td>0.707156</td>\n",
       "      <td>0.695160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>0.582269</td>\n",
       "      <td>0.709447</td>\n",
       "      <td>0.698570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.577919</td>\n",
       "      <td>0.708429</td>\n",
       "      <td>0.699741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>0.651652</td>\n",
       "      <td>0.674051</td>\n",
       "      <td>0.654552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.431900</td>\n",
       "      <td>0.666793</td>\n",
       "      <td>0.684492</td>\n",
       "      <td>0.672811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.442800</td>\n",
       "      <td>0.666465</td>\n",
       "      <td>0.680672</td>\n",
       "      <td>0.675517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.777209</td>\n",
       "      <td>0.673033</td>\n",
       "      <td>0.661096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.809427</td>\n",
       "      <td>0.665139</td>\n",
       "      <td>0.653557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.798089</td>\n",
       "      <td>0.676853</td>\n",
       "      <td>0.663007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.907359</td>\n",
       "      <td>0.659537</td>\n",
       "      <td>0.648495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>1.006727</td>\n",
       "      <td>0.657499</td>\n",
       "      <td>0.642044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.992413</td>\n",
       "      <td>0.656481</td>\n",
       "      <td>0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>1.064947</td>\n",
       "      <td>0.653425</td>\n",
       "      <td>0.643601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>1.120500</td>\n",
       "      <td>0.647313</td>\n",
       "      <td>0.639225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>1.114988</td>\n",
       "      <td>0.652661</td>\n",
       "      <td>0.638050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>1.220093</td>\n",
       "      <td>0.648077</td>\n",
       "      <td>0.638444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>1.310778</td>\n",
       "      <td>0.648841</td>\n",
       "      <td>0.639565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>1.294463</td>\n",
       "      <td>0.654953</td>\n",
       "      <td>0.646074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>1.308861</td>\n",
       "      <td>0.669213</td>\n",
       "      <td>0.657574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>1.396459</td>\n",
       "      <td>0.664120</td>\n",
       "      <td>0.652770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>1.416045</td>\n",
       "      <td>0.651133</td>\n",
       "      <td>0.639241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>1.445819</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.637669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>1.453815</td>\n",
       "      <td>0.651133</td>\n",
       "      <td>0.637222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>1.498427</td>\n",
       "      <td>0.655971</td>\n",
       "      <td>0.640287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>1.513532</td>\n",
       "      <td>0.651642</td>\n",
       "      <td>0.638925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>1.555899</td>\n",
       "      <td>0.658263</td>\n",
       "      <td>0.650723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>1.557432</td>\n",
       "      <td>0.653934</td>\n",
       "      <td>0.642375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>1.557866</td>\n",
       "      <td>0.650115</td>\n",
       "      <td>0.639135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arabic-bbpe, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arabic-bbpe and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3927 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 03:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.619600</td>\n",
       "      <td>0.591031</td>\n",
       "      <td>0.695187</td>\n",
       "      <td>0.682534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.589700</td>\n",
       "      <td>0.577393</td>\n",
       "      <td>0.703845</td>\n",
       "      <td>0.678430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.575674</td>\n",
       "      <td>0.711485</td>\n",
       "      <td>0.693550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.544700</td>\n",
       "      <td>0.578697</td>\n",
       "      <td>0.707156</td>\n",
       "      <td>0.695160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>0.582269</td>\n",
       "      <td>0.709447</td>\n",
       "      <td>0.698570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.577919</td>\n",
       "      <td>0.708429</td>\n",
       "      <td>0.699741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>0.651652</td>\n",
       "      <td>0.674051</td>\n",
       "      <td>0.654552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.431900</td>\n",
       "      <td>0.666793</td>\n",
       "      <td>0.684492</td>\n",
       "      <td>0.672811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.442800</td>\n",
       "      <td>0.666465</td>\n",
       "      <td>0.680672</td>\n",
       "      <td>0.675517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.777209</td>\n",
       "      <td>0.673033</td>\n",
       "      <td>0.661096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.809427</td>\n",
       "      <td>0.665139</td>\n",
       "      <td>0.653557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.798089</td>\n",
       "      <td>0.676853</td>\n",
       "      <td>0.663007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.907359</td>\n",
       "      <td>0.659537</td>\n",
       "      <td>0.648495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>1.006727</td>\n",
       "      <td>0.657499</td>\n",
       "      <td>0.642044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.992413</td>\n",
       "      <td>0.656481</td>\n",
       "      <td>0.640009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>1.064947</td>\n",
       "      <td>0.653425</td>\n",
       "      <td>0.643601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>1.120500</td>\n",
       "      <td>0.647313</td>\n",
       "      <td>0.639225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>1.114988</td>\n",
       "      <td>0.652661</td>\n",
       "      <td>0.638050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>1.220093</td>\n",
       "      <td>0.648077</td>\n",
       "      <td>0.638444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>1.310778</td>\n",
       "      <td>0.648841</td>\n",
       "      <td>0.639565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>1.294463</td>\n",
       "      <td>0.654953</td>\n",
       "      <td>0.646074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>1.308861</td>\n",
       "      <td>0.669213</td>\n",
       "      <td>0.657574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>1.396459</td>\n",
       "      <td>0.664120</td>\n",
       "      <td>0.652770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>1.416045</td>\n",
       "      <td>0.651133</td>\n",
       "      <td>0.639241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>1.445819</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.637669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>1.453815</td>\n",
       "      <td>0.651133</td>\n",
       "      <td>0.637222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>1.498427</td>\n",
       "      <td>0.655971</td>\n",
       "      <td>0.640287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>1.513532</td>\n",
       "      <td>0.651642</td>\n",
       "      <td>0.638925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>1.555899</td>\n",
       "      <td>0.658263</td>\n",
       "      <td>0.650723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>1.557432</td>\n",
       "      <td>0.653934</td>\n",
       "      <td>0.642375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>1.557866</td>\n",
       "      <td>0.650115</td>\n",
       "      <td>0.639135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faisalq/bert-base-arabic-bbpe</td>\n",
       "      <td>0.708429</td>\n",
       "      <td>0.699741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>faisalq/bert-base-arabic-senpiece</td>\n",
       "      <td>0.717087</td>\n",
       "      <td>0.704580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/bert-base-arabic-wordpiece</td>\n",
       "      <td>0.716323</td>\n",
       "      <td>0.704578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  Accuracy        F1\n",
       "0       faisalq/bert-base-arabic-bbpe  0.708429  0.699741\n",
       "3   faisalq/bert-base-arabic-senpiece  0.717087  0.704580\n",
       "6  faisalq/bert-base-arabic-wordpiece  0.716323  0.704578"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell-1  \n",
    "#load and clean the data (removing diacritics and unwanted text)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "log_file = 'SaudiIrony.txt'\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('SaudiIrony/SaudiIrony.csv', encoding='utf-8', engine='python') #, quotechar=\"'\"  , quoting=3\n",
    "display(df.columns)\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "df['Tweets with Decoded emojis'] = df['Tweets with Decoded emojis'].str.replace('\\r\\n', ' ', regex=False)\n",
    "df['Final Annotation'] = df['Final Annotation'].str.replace('\\r\\n', '', regex=False)\n",
    "# df_test = pd.concat([df2, df3], axis=0, ignore_index=True)\n",
    "\n",
    "display(df[:4])\n",
    "\n",
    "# ['Tweet ID', 'Tweets with Decoded emojis', 'Final Annotation']\n",
    "df['text'] = df['Tweets with Decoded emojis']\n",
    "\n",
    "df = df[df['text'] != '']\n",
    "\n",
    "# dfx = df[df['text'] == '']\n",
    "\n",
    "# display(dfx)\n",
    "# display(len(dfx))\n",
    "\n",
    "# return \n",
    "\n",
    "\n",
    "\n",
    "classes = set(df['Final Annotation'].values)\n",
    "display(classes)\n",
    "\n",
    "df['Final Annotation'] = df['Final Annotation'].astype('category')\n",
    "df['label'] = df['Final Annotation'].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "df = df[['text', 'label']]\n",
    "\n",
    "\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "# display(len(df_test))\n",
    "\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "# ds_v = Dataset.from_pandas(df_test)\n",
    "\n",
    "# ds = ds['train']\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "display(ds)\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "# classes_num = 6\n",
    "# display(classes_num)\n",
    "# display(ds)\n",
    "\n",
    "\n",
    "models = ['faisalq/bert-base-arabic-wordpiece', 'faisalq/bert-base-arabic-senpiece',\n",
    "          'faisalq/bert-base-arabic-bbpe']\n",
    "\n",
    "\n",
    "for model_name in models:\n",
    "    for i in range(3):\n",
    "        print(f'{model_name}, try:{i}')\n",
    "              \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = BertForSequenceClassification.from_pretrained(model_name,\n",
    "                                                              num_labels=classes_num).to('cuda')                                                 \n",
    "        dataset_train = ds['train']\n",
    "        dataset_validation = ds['test']                                                    \n",
    "        \n",
    "      \n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            return tokenizer(examples['text'], truncation=True, padding=\"max_length\",\n",
    "                            max_length=max_sequence_length, add_special_tokens=True)\n",
    "        \n",
    "        \n",
    "        dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "        dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "        \n",
    "       \n",
    "        \n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)    \n",
    "            acc = accuracy_score(labels, predictions)        \n",
    "            f1 = f1_score(labels, predictions, average='macro')   \n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{model_name},{acc},{f1}\\n')\n",
    "            return {'accuracy': acc, 'f1_score': f1}\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        epochs = 10\n",
    "        save_steps = 10000 #save checkpoint every 10000 steps\n",
    "        batch_size = 256\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = 'bert/',\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs = epochs,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            save_steps = save_steps,\n",
    "            save_total_limit = 1, #only save the last 5 checkpoints\n",
    "            fp16=True,\n",
    "            learning_rate = 5e-5,  # 5e-5 is the default\n",
    "            logging_steps = 20, #50_000\n",
    "            evaluation_strategy = 'steps',\n",
    "            # evaluate_during_training = True,\n",
    "            eval_steps = 20\n",
    "            \n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args = training_args,\n",
    "            # data_collator=data_collator,\n",
    "            train_dataset=dataset_train,\n",
    "            eval_dataset=dataset_validation,\n",
    "            compute_metrics = compute_metrics\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # trainer.train(resume_from_checkpoint=True)\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv('SaudiIrony_results.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b7f13-c4fa-4355-9192-11d71fbab952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382f88d-15fb-48d8-8b29-f328f6817a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb4923-7e46-4c22-a4b7-0321fdc9c707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
